<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Session 4.1: Hierarchical Models, Priors and Model Checking</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <!-- (Re)Defines a bunch of LaTeX commands that can then be used directly in the .Rmd file as '\command{...}' -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        /* This enables color macros */
        extensions: ["color.js"],
        Macros: {
          /* Probability & mathematical symbols */
          Pr: "{\\style{font-family:inherit; font-size: 110%;}{\\text{Pr}}}",
          exp: "{\\style{font-family:inherit; font-size: 105%;}{\\text{exp}}}",
          log: "{\\style{font-family:inherit; font-size: 105%;}{\\text{log}}}",
          ln: "{\\style{font-family:inherit; font-size: 105%;}{\\text{ln}}}",
          logit: "{\\style{font-family:inherit; font-size: 100%;}{\\text{logit}}}",
          HR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{HR}}}",
          OR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{OR}}}",
          E: "{\\style{font-family:inherit; font-size: 105%;}{\\text{E}}}",
          Var: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Var}}}",
          Cov: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Cov}}}",
          Corr: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Corr}}}",
          DIC: "{\\style{font-family:inherit; font-size: 105%;}{\\text{DIC}}}",
          se: "{\\style{font-family:inherit; font-size: 100%;}{\\text{se}}}",
          sd: "{\\style{font-family:inherit; font-size: 100%;}{\\text{sd}}}",
          kld: "{\\style{font-family:inherit; font-size: 100%;}{\\text{kld}}}",
          /* Distributions */
          dnorm: "{\\style{font-family:inherit;}{\\text{Normal}}}",
          dt: "{\\style{font-family:inherit;}{\\text{t}}}",
          ddirch: "{\\style{font-family:inherit;}{\\text{Dirichlet}}}",
          dmulti: "{\\style{font-family:inherit;}{\\text{Multinomial}}}",
          dbeta: "{\\style{font-family:inherit;}{\\text{Beta}}}",
          dgamma: "{\\style{font-family:inherit;}{\\text{Gamma}}}",
          dbern: "{\\style{font-family:inherit;}{\\text{Bernoulli}}}",
          dbin: "{\\style{font-family:inherit;}{\\text{Binomial}}}",
          dpois: "{\\style{font-family:inherit;}{\\text{Poisson}}}",
          dweib: "{\\style{font-family:inherit;}{\\text{Weibull}}}",
          dexp: "{\\style{font-family:inherit;}{\\text{Exponential}}}",
          dlnorm: "{\\style{font-family:inherit;}{\\text{logNormal}}}",
          dunif: "{\\style{font-family:inherit;}{\\text{Uniform}}}",
          /* LaTeX formatting */
          bm: ["{\\boldsymbol #1}",1],
          /* These create macros to typeset numbers in maths with the basic font */
          0: "{\\style{font-family:inherit; font-size: 105%;}{\\text{0}}}",
          1: "{\\style{font-family:inherit; font-size: 105%;}{\\text{1}}}",
          2: "{\\style{font-family:inherit; font-size: 105%;}{\\text{2}}}",
          3: "{\\style{font-family:inherit; font-size: 105%;}{\\text{3}}}",
          4: "{\\style{font-family:inherit; font-size: 105%;}{\\text{4}}}",
          5: "{\\style{font-family:inherit; font-size: 105%;}{\\text{5}}}",
          6: "{\\style{font-family:inherit; font-size: 105%;}{\\text{6}}}",
          7: "{\\style{font-family:inherit; font-size: 105%;}{\\text{7}}}",
          8: "{\\style{font-family:inherit; font-size: 105%;}{\\text{8}}}",
          9: "{\\style{font-family:inherit; font-size: 105%;}{\\text{9}}}",
          /* Health economics quantities */
          icer: "{\\style{font-family:inherit; font-size: 100%;}{\\text{ICER}}}",
          nb: "{\\style{font-family:inherit; font-size: 100%;}{\\text{NB}}}",
          ol: "{\\style{font-family:inherit; font-size: 100%;}{\\text{OL}}}",
          ceac: "{\\style{font-family:inherit; font-size: 100%;}{\\text{CEAC}}}",
          evpi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPI}}}",
          evppi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPPI}}}",
          evsi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVSI}}}"
        }
      }
    });
    </script>
    <link rel="stylesheet" href="../assets/beamer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">





class: title-slide

# Session 4.1: Hierarchical Models, Priors and Model Checking&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt; 

## 

###     

### Imperial College London 

&lt;!-- Can also separate the various components of the extra argument 'params', eg as in 
### Imperial College London, , MSc in Epidemiology / Health Data Analytics
--&gt;



---

layout: true  

.my-footer[ 
.alignleft[ 
&amp;nbsp; &amp;copy; Marta Blangiardo | Monica Pirani 
]
.aligncenter[
MSc in Epidemiology / Health Data Analytics 
]
.alignright[
Imperial College London, NA 
]
] 


&lt;style&gt;
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
&lt;/style&gt;


---

# Learning Objectives

After this session you should be able to:

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Understand the different modelling assumptions for hierarchical data

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Be able to specify a hierarchical model for Poisson data

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Be able to perform prediction in a Bayesian approach

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Distinguish and choose between several prior distributions for the precision/variance parameter 

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Use the DIC/WAIC as tools for model selection.

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

The topics treated in this lecture are covered in Chapter 5 of Blangiardo and Cameletti (2015).

---

# Outline 

1\. [What are hierarchical models](#hierarchical)

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

2\. [Different modelling assumptions](#modelling-assumptions)

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

3\. [Parameter interpretation](#Interpretation)

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

4\. [Hierarchical regression](#Hier-regression)


&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

6\. [Choice of prior](#Prior)

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

7\. [Model selection](#Modelselection)
---

name: hierarchical

&lt;span style="display:block; margin-top: 250px ;"&gt;&lt;/span&gt;

.myblue[.center[.huge[
**What are hierarchical models**]]]


---

# What are hierarchical models?

**Hierarchical model** is a very broad term that refers to wide range of
model set-ups

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
 
- Multilevel models

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Random effects models

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Random coefficient models

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Variance-component models

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- Mixed effect models

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

.content-box-blue[**Key feature**: Hierarchical models are statistical models that provide a
formal framework for analysis with a complexity of structure that matches the system being studied.]

---

# The hierarchical approach
 
- Attempt to capture (model) and understand the structure of the data 

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

--

- Is flexible: 

  - all sources of correlation and heterogeneity can be incorporated in a modular fashion, in particular by the introduction of unit-specific parameters
  - can be combined with other types of models, e.g. for missing data or measurement error

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

--

- We wish to make inference on models with many parameters `\((\lambda_1,\ldots,\lambda_N)\)` measured on N units (individuals, areas, time-points, etc.) which are related or connected by the structure of the problem.

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

--

- Unit specific parameters will .red[borrow strength] from corresponding parameters associated with the other units

---

# Motivating example: Disease mapping
  
- To summarise spatial and spatio-temporal variation in disease risk

- **Question**: Which areas have particularly high or low disease rates?

- **Question**: Can we explain some of the variation in disease rates by
area-level covariates?
--
  
- Data are the observed `\((y_{i})\)` and expected number of cases in area `\(i\)`: `\(E_{i} = \sum_k n_{ik} r_k\)`, where `\(r_k\)` reference rate for stratum `\(k\)` (age, sex,...)
 
- Rare disease and/or small areas: Poisson framework
  
`$$y_i \sim \text{Poisson}(\rho_i E_i)$$`

&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

where `\(\rho_i\)` is the **unknown RR** in area `\(i\)`

.content-box-beamer[

### Non smoothed estimates of the RR (SMR or SIR)
`\begin{align*}
\text{SMR}_i &amp;=\frac{y_i}{E_i}\\ 
\hbox{Var}(\hbox{SMR}_i) &amp;=  \frac{y_i}{E_i^2}
\end{align*}`
]
  
&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

--
    
- .red[very imprecise: areas with small] `\(\class{red}{E_i}\)` .red[have high associated variance]    

- .red[estimated independently: makes no use of risk estimates in other areas of the map]

---

# Motivating example: Disease mapping

*Example*: 

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- observed cases of lip cancer `\(y_i\)` diagnosed in Scotland in 1975-1980 at county level `\(i=1,\ldots,56\)` areas

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

- expected number of cases `\(E_i\)` are also available using age/sex standardised reference rates and population counts:

--
  
Assume a Poisson likelihood for the disease counts in each area:
  
`$$y_i\sim \text{Poisson}(\lambda_i)\qquad\qquad \lambda_i = \rho_i E_i \qquad\qquad i=1,\ldots,56$$`
&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;
   
- We have 56 parameters `\(\rho_i\)` (one for each area). What prior do we specify on `\(\rho_i\)`?    

---


# Expected numbers of cases - definition
- Expected number of cases if the population had the same stratum-specific mortality/incidence rates as in a reference area
- Adjustments (strata): age, gender ...

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;
*Indirect standardisation*: `\(E_i = \sum_k n_{ik} r_k\)`
with
- `\(r_k\)`: disease rate for stratum `\(k\)` in the reference population
- `\(n_{ik}\)`: population at risk in area `\(i\)`, stratum `\(k\)`

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

.red[If internal comparison:] `\(\color{red}{\sum_{i=1}^N O_i = \sum_{i=1}^N E_i}\)`
&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

*Direct standardisation*: apply the disease rate in the population of interest (e.g. UK) to a standard population e.g. European standard population

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

*External comparison*: if the reference population is not the population of the study of interest. For example, to calculate the expected numbers in London, risks in England could be used.

---

# Expected numbers of cases - calculation

&lt;center&gt;&lt;img src=./img/Expected.png width='60%' title='Lung cancer incidence in males, all ages, using the rates in England and Wales as reference, for the period 1985-2009'&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

`$$\hbox{SIR}_A=\frac{118}{126.38}=0.93$$` 

&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

- Fewer incident cases of lung cancer for males in ward A than expected in EW after adjusting for differences in age.

- In R we can perform indirect standardization using the package `SpatialEpi` (we will see it in the Practical in week 6).

---

name: modelling-assumptions

&lt;span style="display:block; margin-top: 250px ;"&gt;&lt;/span&gt;

.myblue[.center[.huge[
**Modelling assumptions**]]]

---


# Different modelling assumptions

.content-box-beamer[

### Identical parameters
- Assume `\(\rho_i = \rho\)` 

`\(\rightsquigarrow\)` all  the  data can be pooled and the individual areas ignored.

- Assume a prior `\(\rho \sim \text{Gamma}(1,1)\)`

`\(\rightsquigarrow\)` conjugate prior

]

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- One parameter generates all the observations
&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;
- Very easy to implement as it is conjugate (no need for INLA) and all the data are .red[pooled] to produce one estimate of the parameter of interest
&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;
- Can be unrealistic (it does not take into account differences in the areas)

---

# Different modelling assumptions

.content-box-beamer[

### Independent parameters
- All the `\(\rho_i\)` are unrelated, meaning that the areas are analysed independently 

- Assume a prior `\(\rho_i \sim \text{Gamma}(1,1); \qquad i=1,\ldots,56\)`

`\(\rightsquigarrow\)` individual estimates of `\(\rho_i\)` are likely to be highly variable (unless very large sample sizes)

]

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- Every area is treated separately (No exchange of information between these). Estimates close to SMR `\((\rho_i \approx y_i / E_i)\)`. 
&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;
- Again no need for INLA, conjugacy can be exploited.

---

# Different modelling assumptions

.content-box-beamer[

### Similar (exchangeable) parameters
- All the `\(\rho_i\)` are assumed to be *similar* 

`\(\rightsquigarrow\)` they come from the same distribution (are generated by the same parameters)

- Assume a hierarchical prior `\(\rho_i \sim \text{Gamma}(a,b)\)`

where `\(a\)` and `\(b\)` are unknown parameters and need to be estimated.

]

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- Different levels of analysis
- Allow the exchange of information between different levels as they are all connected to each other
- Assign hyperprior distribution to `\(a\)` and `\(b\)`, for instance `$$a \sim \text{Exp}(1); b\sim \text{Gamma}(1,1)$$` 

---

# Graphical representation of lip cancer hierarchical model

&lt;center&gt;&lt;img src=./img/DAG.png width='100%' title=''&gt;&lt;/center&gt;

---

# A more flexible hierarchical prior for the relative risks
- A gamma random effect prior for the `\(\rho_i\)` is mathematically convenient, but might be restrictive:

  - Covariate adjustment is difficult
  
  - Not possible to allow for spatial correlation between risks in nearby areas

--

  - A Normal random effect prior on the `\(\log \rho_i\)` is more flexible:
 
`\begin{align*}
y_i &amp;\sim \text{Poisson}(\lambda_i = \rho_i E_i)\\
\eta_i &amp;= \log \rho_i = b_0 + v_i\\
v_i &amp;\sim \text{Normal}(0, \sigma^2_v)
\end{align*}`

--

- Need to specify hyperprior distributions for:

- `\(\sigma^2_v\)` (between-area variance), e.g. `\(1/\sigma^2_v \sim \text{Gamma}(1,0.001)\)`
- `\(b_0\)` (mean log relative risk), e.g. `\(b_0 \sim \text{Normal}(0,0.0001)\)` 
&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;
--

### Advantages of this approach:
&lt;span style="display:block; margin-top: -20px ;"&gt;&lt;/span&gt;
Posterior for each `\(v_i\)`

- *borrows strength* from the likelihood contributions of **all** the areas, via their joint influence on the estimate of the unknown population (prior) parameter `\(\sigma^2_v\)` 

&amp;rarr; *global smoothing* of the area RR 

&amp;rarr; reflects our *full uncertainty* about the true values of `\(\sigma^2_v\)`

.content-blue-box[
Such models are called .red[*Hierarchical*] or .red[*Random effects*] or .red[*Multilevel*] models
]

---


name: interpretation

&lt;span style="display:block; margin-top: 250px ;"&gt;&lt;/span&gt;

.myblue[.center[.huge[
**Interpretation**]]]


---

# Parameter interpretation and useful quantities 
- `\(\rho_i\)` is the relative risk for the area i compared to the average area with the same structure in the expected values.

- `\(v_{i}\)` are the random effects. It can also be seen as the latent variable which captures the effect of unknown or unmeasured area level covariates.

- If area level covariates are spatially structured we should take this into account when modelling `\(v_i\)` (we will see it later)

- `\(\text{exp}(v_{i})\)` relative risk in area `\(i\)` compared to the risk for the whole study region

- The variance of the random effects `\(\sigma^2_v\)` reflects the amount of extra-Poisson variation in the data
  
--

&lt;span style="display:block; margin-top: -15px ;"&gt;&lt;/span&gt;

- A useful summary of among unit variability in a Poisson hierarchical model is to rank the random effects and calculate the difference between two units at opposite extremes

- Suppose we consider the `\(5^{th}\)` and `\(95^{th}\)` percentiles of the area relative risk distribution

- let `\(q_{5\%} = \rho_{5\%}\)` denote the log relative risk of outcome for the area ranked at the `\(5^{th}\)` percentile

- let `\(q_{95\%} = \rho_{95\%}\)` denote the log relative risk of outcome  for the area ranked at the `\(95^{th}\)` percentile

.content-box-beamer[
### Quantile ratio
`$$\text{QR}_{90} = \text{exp}(q_{95\%}-q_{5\%})$$` 
is the relative risk of outcome  between the top and bottom 5% of areas
]

---

#Lip cancer dataset


```r
&gt; LipCancer &lt;- read.csv("scotlip.csv")
&gt; LipCancer
```



```
# A tibble: 6 × 11
  CODENO       AREA PERIMETER RECORD_ID DISTRICT NAME          CODE      y    POP     E     x
   &lt;int&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;int&gt;    &lt;int&gt; &lt;chr&gt;         &lt;chr&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt; &lt;int&gt;
1   6126  974002000    184951         1        1 Skye-Lochalsh w6126     9  28324  1.38    16
2   6016 1461990000    178224         2        2 Banff-Buchan  w6016    39 231337  8.66    16
3   6121 1753090000    179177         3        3 Caithness     w6121    11  83190  3.04    10
4   5601  898599000    128777         4        4 Berwickshire  w5601     9  51710  2.53    24
5   6125 5109870000    580792         5        5 Ross-Cromarty w6125    15 129271  4.26    10
6   6554  422639000    118433         6        6 Okney         w6554     8  53199  2.4     24
```

- `DISTRICT` identifies the area
- `y` identifies the counts of cancer cases
- `E` identifies the expected cases of cancer using the entire region under study as reference
- `x` identifies the exposure to sun (percentage of agriculture , farming and fishery works)
 
---

# In `R-INLA` 

We first populate the `formula` environment


```r
&gt; formula.inla &lt;- y ~ 1 + 
+   f(RECORD_ID,model="iid", hyper=list(prec=list(prior="loggamma",
+   	param=c(1,0.01))))
```

- The model specification is exactly the same as in GLM;
- Anything with `f(.)` specifies a random effect; in this case `iid` represents the exchangeable structure. 

Then we run the model through


```r
&gt; lipcancer.poisson &lt;- inla(formula.inla,family="poisson",
+                           data=LipCancer, E=E,
+                           control.predictor=list(compute=TRUE),
+                           control.compute=list(config=TRUE),
+                           control.fixed=list(mean.intercept=0,prec.intercept=0.00001))
```
&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;
Note that 

- `control.fixed` allows to specify the parameters of the prior for the fixed effects (intercept)
- `control.predictor` tells `INLA` to include the linear predictor estimation ( the parameters of the prior for the fixed effects (intercept)) useful for prediction - see later)
- `control.compute` allows to include model selection indexes, as well as to draw samples from the joint posterior

---

# Results for lip cancer in Scotland example

- `\(\text{exp}(b_0 + v_i)\)` is the relative risk of lip cancer in area `\(i\)` relative to the average area with the same age/sex structure (see map)

- `\(\sigma_v\)` is the between-area standard deviation of log relative risk of lip cancer

- As in INLA we get the precision we need to convert it into standard deviation using

```r
&gt; sigma.v&lt;- inla.tmarginal(function(x) sqrt(1/x),
+ 			lipcancer.poisson$marginals.hyperpar[[1]])
```

And we can calculate quintiles with

```r
&gt; inla.qmarginal(seq(0,1,0.2),sigma.v)
```

```
[1] 0.5018776 0.6746031 0.7255274 0.7731827 0.8332256 1.1426164
```

---

# Maps: comparing SMR with smoothed estimates




.pull-left[
###SMR
&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;
&lt;img src="./img/ggplot1-1.png" &gt;
]

.pull-right[
###Posterior mean
&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;
&lt;img src="./img/ggplot2-1.png" &gt;
]

---

# Quantile ratios

To obtain the quantile ratio we need to follow these steps:

1\. Obtain the **join posterior distribution** for the model under consideration
&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;

```r
&gt; joint.post &lt;- inla.posterior.sample(100,lipcancer.poisson)
&gt; names(joint.post[[1]])
```

```
[1] "hyperpar" "latent"   "logdens" 
```

```r
&gt; joint.post[[1]]$latent[1:3,]
```

```
Predictor:1 Predictor:2 Predictor:3 
   1.855751    1.603242    1.048860 
```
&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;
Note that:
- `joint.post` is a list of 100 elements and each element includes  a value from

1\. the joint posterior distribution for the hyperparameters `joint.post$hyperpar`

2\. joint posterior distribution for the linear predictor `\(\bm{\eta}\)` in `joint.post$latent` (row 1 to N) 

3\. joint posterior distribution for the random effects `\(\bm{v}\)` in `joint.post$latent` (N +1 to 2N)

---

# Quantile ratios

2\. For each iteration rank the areas based on their `\(v_i\)` values

```r
&gt; joint.v &lt;- matrix(NA,56,100)
&gt; for(i in 1:100){
+   joint.v[,i]&lt;- joint.post[[i]]$latent[57:112]
+ }
```
- Calculate `\(v_3\)` and `\(v_{53}\)` (5% and 95%) and build the ratio

```r
&gt; v5perc &lt;- apply(joint.v,2, function(x) quantile(x,0.05))
&gt; v95perc &lt;- apply(joint.v,2, function(x) quantile(x,0.95))
&gt; QR90&lt;- mean(exp(v95perc-v5perc))
&gt; QR90
```

```
[1] 10.56443
```

- The `\(QR90\)` points towards a large spatial variability. 

---

# SMR versus posterior mean RR for selected areas


&lt;center&gt;&lt;img src=./img/shrinkage-1.png width='50%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

- Comparing the SMR and the area level posterior mean from the model shows a shrinkage towards the global (national mean) 
---

name: Hier-regression

&lt;span style="display:block; margin-top: 250px ;"&gt;&lt;/span&gt;

.myblue[.center[.huge[
**Hierarchical Regression**]]]


---

# Regression in `INLA`

It is easy to move from hierarchical models to regression models with random effects. 

&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;

**Example**: We consider a dataset which contains measurements on whether Swiss Willow Tits were found on three separate visits in several locations across Switzerland. We want to understand the relationship between the presence of the birds, elevation and forest cover. 

--

We specify a random effect logistic model 

`\begin{eqnarray*}
 y_i &amp;\sim&amp; \text{Bernoulli}(\pi_i , 1)\\
\text{logit}(\pi_i) &amp;=&amp; b_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + v_i\\
v_i &amp;\sim&amp; \text{Normal}(0, \sigma^2_v)
\end{eqnarray*}`

where `\(x_{1i}\)` , `\(x_{2i}\)` are the elevation and forest cover for the i `\(-th\)` visit. Note that `\(b_0\)` , `\(\beta_1\)` , `\(\beta_2\)`, `\(1/\sigma^2_v\)` are given independent "noninformative" priors. 


---

# `R` code to prepare the dataset


```r
&gt; swt = read.csv('swt.csv', stringsAsFactors = TRUE)
```



.pull-left[

```r
&gt; head(swt)
```

```
  rep.1 rep.2 rep.3 c.2 c.3 elev forest dur.1 dur.2 dur.3 length alt
1     0     0     0   0   0  420      3   240    58    73    6.2 Low
2     0     0     0   0   0  450     21   160    39    62    5.1 Low
3     0     0     0   0   0 1050     32   120    47    74    4.3 Med
4     0     0     0   0   0 1110     35   180    44    71    5.4 Med
5     0     0     0   0   0  510      2   210    56    73    3.6 Low
6     0     0     0   0   0  630     60   150    56    73    6.1 Low
```

```r
&gt; # Add ID
&gt; swt$ID &lt;- seq(1,length(swt[,1]))
```
]

.pull-right[

```r
&gt; # Move from wide to long format
&gt; library(tidyr)
&gt; swt_long &lt;- gather(swt, outings, presence, rep.1:rep.3, factor_key=TRUE)
&gt; head(swt_long)
```

```
  c.2 c.3 elev forest dur.1 dur.2 dur.3 length alt ID outings presence
1   0   0  420      3   240    58    73    6.2 Low  1   rep.1        0
2   0   0  450     21   160    39    62    5.1 Low  2   rep.1        0
3   0   0 1050     32   120    47    74    4.3 Med  3   rep.1        0
4   0   0 1110     35   180    44    71    5.4 Med  4   rep.1        0
5   0   0  510      2   210    56    73    3.6 Low  5   rep.1        0
6   0   0  630     60   150    56    73    6.1 Low  6   rep.1        0
```
]

---

# `R-INLA` code

.pull-left[

```r
&gt; formula&lt;- presence ~ elev + forest + f(ID,model="iid")
&gt; model.regression &lt;- inla(formula,data=swt_long,family="binomial", Ntrials=1)
&gt; model.regression$summary.fixed
```

```
                    mean           sd  0.025quant     0.5quant   0.975quant         mode          kld
(Intercept) -5.787771531 0.4732679419 -6.71580340 -5.787771402 -4.859740393 -5.787771401 5.526128e-11
elev         0.002336135 0.0002224772  0.00189988  0.002336135  0.002772391  0.002336135 5.525786e-11
forest       0.042872372 0.0046380369  0.03377765  0.042872371  0.051967107  0.042872371 5.525203e-11
```
]

.pull-right[

```r
&gt; plot(model.regression$summary.random$ID$mean)
```

&lt;img src="./img/swt-plot-1.png" &gt;
]

---

name: Prior

&lt;span style="display:block; margin-top: 250px ;"&gt;&lt;/span&gt;

.myblue[.center[.huge[
**Choice of prior**]]]

---

# How to specify priors?

- *Relatively* easy to specify priors on regression parameters
  - Typical choice is a Normal distribution
  - Tuning the variance it can be more or less informative 
  - .alert[The scale of the variable it represents need to be considered]
  
--

&lt;span style="display:block; margin-top: 40px ;"&gt;&lt;/span&gt;

- Variances are more complex (and a bit more controversial)

- In small area studies we usually work with Poisson/Binomial distribution on data - no variance parameter; the main interest is on random effect variance.

--
&lt;span style="display:block; margin-top: 40px ;"&gt;&lt;/span&gt;

- A Gamma `\((\epsilon,\epsilon)\)` can be used on the precision but inference could be sensitive to choice of `\(\epsilon\)`. Typically to ensure vague priors small `\(\epsilon\)` are specified (e.g. 0.1, 0.01). However, this prior has also been criticised (e.g. (Gelman, 2006)) as it has a spike for values around 0.

--

- .red[Careful as "non informative" prior distributions are sensitive to changes of scale.]

---

# Changing the scale

- For instance starting with a Uniform on the standard deviation we end up with a high density on low values for the precision  







&lt;img src="./img/tau_plot-1.png" style="display: block; margin: auto;" width="60%"&gt;

---

# Remember...

- `INLA` parametrises the precision and the default is

`\(\log \left(1/\sigma^2\right) \sim \text{logGamma}(1,0.00005)\)`

- However alternatives can be built, for instance: 

  -  Truncated Normal on log precision (`logtnormal`)
  -  Uniform prior on the standard deviation: as it is not implemented we need to specify it through the `expression` as follows
  
`UN.prior = "expression:
  log_dens = 0 - log(2) - theta / 2;
  return(log_dens);"`


&lt;span style="display:block; margin-top: 50px ;"&gt;&lt;/span&gt;

.content-box-blue[In general we need to be careful to check the level of information (weakly, strong) on the scale we are interested in (e.g. variance) and see what this corresponds on the standard deviation/precision (on which prior is usually specified).
]

See Gómez-Rubio (2020) for more information on how to specify priors in `INLA`.
---

name: Modelselection

&lt;span style="display:block; margin-top: 250px ;"&gt;&lt;/span&gt;

.myblue[.center[.huge[
**Model selection**]]]

---

# Which model?


.center[.content-box-blue[.Large[**All models are wrong, some models are useful.**

G. Box]]]

--
&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

So the question is: how is my model doing?
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
  1. in terms of model assumption
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
  2. compared to other models

--

We can answer the first question using the .red[posterior predictive distribution]

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

We can answer the first question using .red[methods based on the trade-off between a measure of model fit and of model complexity]

---

# Posterior predictive distribution

.red[Main idea: If the combined model assumptions are reasonable, then our posterior model should be able to simulate data that’s similar to the original one]

- Let's assume we want to find the relationship between air pollution and asthma attacks and we collect data of the outcome over 500 days in a London Local Authority 

--

We propose the following model (y=number of asthma attacks, x=level of `\(PM_{10}\)` in the previous 3 days `\(i=1,\ldots,500\)`):

`\begin{align}
y_i &amp;\sim \text{Poisson}(E \rho_i)\\
\text{log}(\rho_i) &amp;= b_0 + \beta x_i + v_i\\
b_0, \beta &amp;\sim N(0,0.001)\\
v_i &amp;\sim N(0,\sigma^2_{v})\\
\text{log}(1/\sigma^2_{v}) &amp;\sim \text{logGamma}(1,0.00005)
\end{align}`

The assumptions are 
  1. that the data are distributed as .red[Poisson]
  2. that there is a linear relationship between air pollution and the log risk of asthma attacks
  3. that the days are similar (we include a random effect)
---

# Posterior predictive distribution

- We run the model and predict observations `\(y^*_1,\ldots,y^*_{500}\)` based on the posterior distribution of the parameters (note that we need to include `control.predictor` in the `inla` function to access these):


```r
&gt; asthma_formula1 &lt;- y ~  x + as.factor(dow) + f(ID, model="iid")
&gt; asthma_model1 &lt;- inla(asthma_formula1, data=data,family="poisson",E = E, control.predictor=list(compute=TRUE),control.compute=list(config=TRUE,dic=TRUE, waic=TRUE, return.marginals.predictor=TRUE))
```


.pull-left[To get the fitted values we run:

```
                          mean        sd 0.025quant  0.5quant 0.975quant      mode
fitted.Predictor.001  7.721553 0.5540705   6.632861  7.709413   8.897669  7.701556
fitted.Predictor.002  7.437117 0.5248999   6.438831  7.410661   8.594115  7.380633
fitted.Predictor.003 12.164226 0.8383418  10.515680 12.143800  13.959114 12.131409
fitted.Predictor.004  4.455800 0.3615331   3.795503  4.433741   5.248132  4.401226
fitted.Predictor.005 10.801745 0.7428503   9.401855 10.756458  12.460263 10.702667
```
]


.pull-right[
&lt;img src="./img/unnamed-chunk-7-1.png" style="display: block; margin: auto;" width="75%"&gt;
]

---

# Posterior predictive distribution

Now let's assume we run a different model 

`\begin{align}
y_i &amp;\sim \text{Normal}(E\theta_i, \tau)\\
\theta_i &amp;= b_0 + \beta x_i\\
b_0, \beta &amp;\sim N(0,0.001)\\
\text{log}(1/\sigma^2_{v}) &amp;\sim \text{logGamma}(1,0.00005)
\end{align}`

The assumptions are 
  1. that the data are distributed as .red[Gaussian]
  2. that there is a linear relationship between air pollution and the risk of asthma attacks
  
---

# Posterior predictive distribution

- We run the model and predict observations `\(y^*_1,\ldots,y^*_{500}\)` based on the posterior distribution of the parameters (note that we need to include `control.predictor` and `control.compute` in the `inla` function to access these):


```r
&gt; asthma_formula2 &lt;- y ~ x
&gt; asthma_model2 &lt;- inla(asthma_formula2, data=data,family="gaussian", E=E,
+                       control.predictor=list(link=1,compute=TRUE),
+                       control.compute=list(config=TRUE,dic=TRUE, waic=TRUE, return.marginals.predictor=TRUE))
```



.pull-left[To get the fitted values we run:

```
                          mean        sd 0.025quant  0.5quant 0.975quant      mode
fitted.Predictor.001  6.560510 0.2189402   6.131044  6.560510   6.989977  6.560510
fitted.Predictor.002  9.121423 0.1472614   8.832559  9.121423   9.410286  9.121423
fitted.Predictor.003 10.513605 0.2060378  10.109448 10.513605  10.917762 10.513605
fitted.Predictor.004  4.596248 0.3530635   3.903690  4.596248   5.288807  4.596248
fitted.Predictor.005  9.383114 0.1539674   9.081096  9.383114   9.685131  9.383114
```
]

.pull-right[
&lt;img src="./img/unnamed-chunk-11-1.png" style="display: block; margin: auto;" width="75%"&gt;
]

---

# Comparison 

&lt;span style="display:block; margin-top: 50px ;"&gt;&lt;/span&gt;

- Both models seem reasonable (the predicted values are in line with the observed ones), but there is more of a shift on the right for the Gaussian model (as expected given its symmetric property)

&lt;span style="display:block; margin-top: 50px ;"&gt;&lt;/span&gt;

- Which one is better?

---

# Model comparison: Bayesian p-value

- We can use the posterior predictive distribution to compare to the observed one through a *p-value*

- Let's go back to `asthma_model1` and `asthma_model2` as output of running the `inla` function and use `inla.pmarginal`

.pull-left[

```r
&gt; # Model 1
&gt; Bayesian_p1 &lt;- c()
&gt; model1_sample &lt;- matrix(NA,500,1000)
&gt; model1_pois &lt;- matrix(NA,500,1000)
&gt; 
&gt; for(i in 1:500){
+ model1_sample[i,] &lt;- inla.rmarginal(1000,asthma_model1$marginals.fitted.values[[i]])
+ for(j in 1:1000){
+ model1_pois[i,j] &lt;- rpois(1, model1_sample[i,j])
+ }
+ 
+ Bayesian_p1[i] &lt;- sum(model1_pois[i,]&lt;y[i])/1000
+ }
```


]

.pull-right[
&lt;img src="./img/unnamed-chunk-14-1.png" style="display: block; margin: auto;" width="75%"&gt;
]



- Ideally we would expect a uniform distribution of the p-values which would tell us there is no pattern of over(under) estimation in the prediction

- Here model 1 seems a bit better than model 2

---
# Model comparison: fit vs complexity


- When the interest lays mainly on the prior distribution or on the functional form of some parameters the deviance of the model can be used to evaluate the goodness of fit.

Given the data `\(\bm{y}\)` with distribution  `\(p(\bm{y}\mid \theta)\)`, the deviance of the model is defined as:
`\begin{eqnarray*}
  D(\theta) = -2 \hbox{log} p(\bm{y} \mid \theta)
\end{eqnarray*}`
where `\(\theta\)` identifies the parameter of the likelihood

--

- Ex. `\(y_i \sim \hbox{Bernoulli}(\theta) \rightsquigarrow p(\mathbf{y}\mid \theta) = \prod_{i=1}^n  \left( \begin{array}{c} n_i \\ y_i \end{array} \right) \theta^{y_i} (1-\theta)^{n_i-y_i}\)`

`\(\displaystyle D(\theta) = -2\left[\sum_i y_i \log \theta_i + (n_i-y_i)\log(1-\theta_i)+ \log\left(\begin{array}{c}n_i\\y_i \end{array}\right)\right]\)`


---

# Mean deviance

- The deviance of the model measures the variability linked to the likelihood, ie the probabilistic structure used for the observation (conditional on the parameters)

- This quantity is a random variable in the Bayesian framework, so it is possible to synthesise it through several indexes (mean, median, etc.)

-  Many authors suggested using posterior mean deviance `\((\overline{D}) = E_{\theta\mid y} [D(\theta)]\)` as a measure of fit

**DRAWBACK:**  more complex models will fit the data better and so will have smaller `\(\overline{D}\)`

- Need to have some measure of *model complexity* to trade off against `\(\overline{D}\)`

---

# Deviance Information Criterion - DIC

- Natural way to compare models is to use criterion based on trade-off between the fit of the data to the model and the corresponding complexity of the model

- Deviance Information Criterion, DIC = goodness of fit + complexity of the model

--

  - The fit is measure through the deviance

`$$D(\theta) = -2 \hbox{log} p(\bm{y} \mid \theta)$$` 

--

  - Complexity measured by estimate of the "effective number of parameters" ($p_D$):

&lt;!--  `$$p_D = \textsf{E}_{\theta\mid y}\left[D(\theta)\right] + D(\textsf{E}_{\theta\mid y}\left[\theta \right])$$`
--&gt;

--

  - The DIC is then defined analogously to AIC as

`$$\hbox{DIC} = D(\textsf{E}_{\theta\mid y}\left[\theta \right]) + 2p_D$$`

  - Models with smaller DIC are better supported by the data

- DIC can be monitored in INLA including  `control.compute=list(dic=TRUE)` into the `inla` function.

---

# Back to our example...

We run the model adding the `dic` (here for model 1, it is the same for model 2):

```r
&gt; asthma_model1 &lt;- inla(asthma_formula1, data=data,family="poisson",control.predictor=list(link=1,compute=TRUE), 
+                       control.compute=list(dic=TRUE))
```

And now check the value of the DIC
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

```r
&gt; # Poisson data distribution
&gt; asthma_model1$dic$dic
```

```
[1] 2425.228
```

```r
&gt; # Normal data distribution
&gt; asthma_model2$dic$dic
```

```
[1] 2581.008
```
The first model is without any doubt preferred as the DIC is smaller.

---

# DIC: some drawbacks

The DIC has been criticised over the years, specifically:

1\. `\(p_D\)` is not invariant to reparameterization. For example, we would obtain a (slightly) different value if we parameterized in terms of `\(\sigma\)` or  `\(\log\sigma\)`

2\. It is not based on a proper predictive criterion

3\. Issues when there are missing data

See (Spiegelhalter, Best, Carlin, and Van der Linde, 2014) for a complete description of the criticisms.

--

&lt;span style="display:block; margin-top: 50px ;"&gt;&lt;/span&gt;

What is the alternative?

---

#Watanabe AIC - WAIC

- Considers the posterior predictive mean and variance (on the log scale)

- Linked to cross-validation

- Similarly to DIC:

  - WAIC has a model-fit and model-complexity components
  - Smaller WAIC indicates the preferred model

--


- Let `\(m_i\)` and `\(v_i\)` be the posterior predictive mean and variance for the 
`\(i^{th}\)` unit
- The effective model size is 
	`$$p_W = \sum_{i=1}^nv_i$$` 
	&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt;
	
- The criteria is 
	`$$WAIC = -2\sum_{i=1}^nm_i + 2p_W$$`
- The WAIC is readily available in `INLA` using `control.compute=list(waic=TRUE)` 


---

# Back to our example...

We run the model adding the `waic` (here for model 1, it is the same for model 2):

```r
&gt; asthma_model1 &lt;- inla(asthma_formula1, data=data,family="poisson",control.predictor=list(link=1,compute=TRUE), 
+                       control.compute=list(waic=TRUE))
```

And now check the value of the DIC
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

```r
&gt; # Poisson data distribution
&gt; asthma_model1$waic$waic
```

```
[1] 2422.167
```

```r
&gt; # Normal data distribution
&gt; asthma_model2$waic$waic
```

```
[1] 2581.84
```
There is accordance between DIC and WAIC as the first model is still preferred as the WAIC  is smaller.

---



# Summary

- Hierarchical models allow **borrowing of strength** across units

  &amp;rarr; posterior distribution of the unit-parameter borrows strength from the
likelihood contributions for all the units, via their joint influence on
the posterior estimates of the unknown hyper-parameters

  &amp;rarr; improved efficiency
  
- Judgements of exchangeability need careful assessment
  &amp;rarr; units suspected a priori to be systematically different might be
modelled by including relevant covariates so that residual variability
more plausibly reflects exchangeability

- Subgroups of prior interest should be considered separately

--

Careful on the prior specification

- non informative on one scale might be informative on another

- always run some sensitivity analyses changing the prior and investigating how this affect the estimates of parameters of interest

- posterior predictive distribution is useful to check if a model is in line with the data under study

- DIC/WAIC are useful tools for model selection, easy to calculate in INLA

&amp;rarr; bear in mind that they can only be used to compare models - similarly to the AIC they do not have an absolute meaning.

---

# References

Blangiardo, M. and M. Cameletti (2015). _Spatial and spatio-temporal Bayesian models with R-INLA_. John Wiley &amp; Sons.

Gelman, A. (2006). "Prior distributions for variance parameters in hierarchical models". In: _Bayesian Analysis_ 1".3", pp. 515-534.

Gómez-Rubio, V. (2020). _Bayesian inference with INLA_. CRC Press.

Spiegelhalter, D. J., N. G. Best, B. P. Carlin, et al. (2014). "The deviance information criterion: 12 years on". In: _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_ 76.3, pp. 485-493.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url("assets/MRC-Centre-Logo.png");
  background-size: 15% 10%;
  background-repeat: no-repeat;
  position: absolute;
  top:  0.25%; /* 1.135em */
  left: 85%;
  width: 100%;
  height: 100%;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)' +
    ':not(.thankyou-michelle)' +
    ':not(.thankyou-barney)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>


<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
