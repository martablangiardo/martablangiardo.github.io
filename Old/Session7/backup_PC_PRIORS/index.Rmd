---
title: "Session 2.2: Spatial models for small area data: disease mapping and ecological regression"
params: 
   conference: "Advanced Analytics"
   location: "Imperial College London"
   date: January-February 2023
   short_title: "Advanced Analytics"
output:
   xaringan::moon_reader: 
    includes: 
       # This line adds a logo based on the format selected in the file 'assets/include_logo.html'
       in_header: "assets/latex_macros.html" 
       # NB: the actual options (eg placement of the logo and actual logo file) can be changed there
     #  after_body: "assets/insert-logo.html" # Monica commented this
    seal: false
    yolo: no
    lib_dir: libs
    nature:
      beforeInit: ["assets/remark-zoom.js","https://platform.twitter.com/widgets.js"]
      navigation:
        scroll: false # disable slide transitions by scrolling
      highlightStyle: github
      highlightLines: yes
      countIncrementalSlides: no
      ratio: '16:9'
      titleSlideClass:
      - center
      - middle
    self_contained: false 
    css:
    - "assets/beamer.css"
editor_options: 
  chunk_output_type: console
---

```{r global_options, echo = FALSE, include = FALSE}
options(width = 999)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      cache = FALSE, tidy = FALSE, size = "small")
#options(htmltools.preserve.raw = FALSE)
# https://stackoverflow.com/questions/65766516/xaringan-presentation-not-displaying-html-widgets-even-when-knitting-provided-t
```

```{r echo=F, message=FALSE, warning=FALSE, comment=NA}
source("assets/setup.R")
library(INLA)
xaringanExtra::use_panelset()
bibfile=RefManageR::ReadBib("~/Dropbox/TEACHING/YEAR_2023/Advanced_Analytics_2023/Material/Session2.2/Biblio.bib",check = FALSE)
```

class: title-slide

# `r rmarkdown::metadata$title``r vspace("10px")` `r rmarkdown::metadata$subtitle`

## `r rmarkdown::metadata$author`

### `r rmarkdown::metadata$institute`    

### `r rmarkdown::metadata$params$conference`, `r rmarkdown::metadata$params$location` 

<!-- Can also separate the various components of the extra argument 'params', eg as in 
### `r paste(rmarkdown::metadata$params, collapse=", ")`
-->

`r ifelse(is.null(rmarkdown::metadata$params$date),format(Sys.Date(),"%e %B %Y"),rmarkdown::metadata$params$date)`

---

layout: true  

.my-footer[ 
.alignleft[ 
&nbsp; &copy; Marta Blangiardo | Monica Pirani
]
.aligncenter[
`r rmarkdown::metadata$params$short_title` 
]
.alignright[
`r rmarkdown::metadata$params$conference`, `r short_date` 
]
] 

```{css,echo=FALSE, eval=FALSE}
.red {
  color: red;
}
.blue {
  color: 0.14 0.34 0.55;
}

.content-box-blue { background-color: #F0F8FF; }

}
```

---

# Learning Objectives

After this session you should be able to:
   
- Explain the main ideas underlying the use of Bayesian methods for producing spatially smoothed estimates of disease risk in small areas
 
- Describe different priors for spatial random effects 
 
- Explore aetiological hypothesis between a health outcome and exposure based on disease mapping
 
- Describe Poisson regression with spatial random effects for continuous and categorical covariates

- Use `R-INLA` to produce maps of smoothed estimates of disease risk, carry out spatial smoothing of disease risk and specify ecological regression models 


The topics treated in this lecture are covered in:

- Chapter 5-6 of the book **Spatial and Spatio-Temporal Bayesian models with R-INLA**

- Chapter 5 of the book **Geospatial Health Data: Modeling and Visualization with R-INLA and Shiny**  https://www.paulamoraga.com/book-geospatial/index.html
---

# Outline 

`r vspace("30px")`

1\. [Spatial Structure](#spatial-structure)

`r vspace("30px")`

2\. [Example: suicides in London](#Example)

`r vspace("30px")`

3\. [Ecological regression with spatial random effects](#Poisson-regression)

---


# Smoothed estimates of the RR (non spatial)

- Poisson-logNormal model based on the assumption that the observations in the data set are identically distributed and independent

`r vspace("20px")`

- However, data that occur close together in space (or time) are likely to be correlated    
  .red[&rarr; Dependence between observations is a more realistic assumption]

`r vspace("20px")`

- This spatial patterning, or .red[spatial autocorrelation], may be treated as useful information about unobserved influences

`r vspace("20px")`

- Formally, spatial autocorrelation measures the correlation of a variable with itself through space. If $Z_i$ is the attribute $Z$ observed at location $i$, then the term spatial autocorrelation refers to the correlation between $Z_i$ and $Z_j$ 

`r vspace("20px")`

- In other words, it quantifies the degree of which observations, at spatial locations, are similar to nearby observations.

`r vspace("20px")`

- Ignoring this dependence can lead to biased and inefficient inference    
  .red[&rarr; Smooth in space] prior distribution for the random effects should allow for spatial correlation

---

name: spatial-structure
  
`r vspace("250px")`

.myblue[.center[.huge[
**Spatial structure**]]]

---

# Building a spatial model

- Specify the distribution of each random effect as if we knew the values of the spatial random effects in .red[neighbouring areas]

`r vspace("20px")`

- We have a conditional specification since we are conditioning on knowing the neighbours

`r vspace("20px")`

- We need a rule for determining the neighbours of each area (the most popular one is based on contiguity)

`r vspace("20px")`

- We specify a conditional autoregressive (CAR) model to capture the spatial structure

---

# Spatial neighbours 

- Key to analyse lattice (or regional) structures is the concept of .blue[spatial connectivity] or .blue[spatial proximity]


- Let $i$ and $j$ index two members of the lattice (i.e. two locations such as two countries, or two districts etc.)


- With each pair of sites, we associate a .red[weight] $w_{ij}$, so that the spatial weights express the neighbour structure between the observations


- Now, let $N$ be the total number of areal units. The spatial relationship between the areas is represented as an adjacency matrix $\mathbf{W}$ with dimensions $N \times N$, where the entries $w_{ij}$ of the matrix are the spatial weights:

 `r include_fig("W.png",width="35%",title="")`

- In its simple form, $w_{ij}=1$ if areas $i$ and $j$ are adjacent, 0 otherwise


- The diagonal elements of $\mathbf{W}$ are zero, that is $w_{ii}=0$

---
# Weights based on contiguity

Operationally, we can distinguish between a .blue[rook (A)] and a .blue[queen (B)] criterion of contiguity between areas (in analogy to the moves allowed for the such-named pieces on a chess board):

`r vspace("25px")`

`r include_fig("Weights.jpg",width="35%",title="")`

- The .blue[rook] criterion defines neighbours by the existence of a common edge between two spatial units


- The .blue[queen] criterion defines neighbours as spatial units sharing a common edge or a common vertex

---
# Example of neighbours computation in R

We need to define:

- Neighbour connectivity (who is neighbour?)

- Neighbour weights (how much does the neighbour matter?)

- To do so, we can work with the package `spdep` and we use the function `poly2nb` to define neighbour connectivity according to rook or queen criterion (contiguity neighbours)

- Also, the function `nb2listw` defines spatial weights for neighbours lists, while `nb2mat` defines spatial weights matrices 

---
- We compute a neighbourhood structures for Luxembourg, one of the smallest country in Europe. We use the shapefile for Luxembourg available in the R package `raster`

```{r lux, echo=TRUE, include=TRUE,eval=TRUE}
library(raster); library(spdep); library(mapview)

# Read in Luxembourg shapefile from R package raster
lux = shapefile(system.file("external/lux.shp", package="raster"))
summary(lux)
```
---

- We plot of Luxembourg divided into 12 cantons and display their name

```{r lux_plot, echo=TRUE, include=TRUE,eval=FALSE}
par(mar=c(0,0,0,0)) # par sets or adjusts plotting parameters,
                    # while the parameter mar stands for margin size 
plot(lux, border=3, col=terrain.colors(length(lux)), axes=F)
text(lux,"NAME_2",cex=0.5)
```

`r include_fig("Lux_map3.jpeg",width="40%",title="")`


Note that we can also generate a vector of $n$ contiguous colors using the functions `rainbow(n)`, `heat.colors(n)`, `terrain.colors(n)`, `topo.colors(n)`, and `cm.colors(n)`.
---

- An interactive map of Luxembourg can be obtained using `mapview` package
```{r lux_plot2, echo=TRUE, include=TRUE,eval=TRUE, fig.width=4, fig.height=5}
mapView(lux)
```

---
- We compute contiguity-based neighbors using `poly2nb` function (here rook's move contiguity is used)

```{r lux2, echo=TRUE, include=TRUE,eval=TRUE}
w.rook = poly2nb(lux, row.names=lux$ID_2, queen=FALSE)
w.rook
```
- The `nb` object w.rook lists for each polygon the neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:
```{r lux3, echo=TRUE, include=TRUE,eval=TRUE}
w.rook[[1]]
```

.pull-left[
```{r echo=TRUE, eval=FALSE}
par(mar=c(0,0,0,0)) 
plot(lux, border=3, 
     col=terrain.colors(length(lux)), 
     axes=F)
text(lux,"ID_2",cex=1)
```
]

.pull-right[
`r include_fig("Lux_map.jpeg",width="51%")`
]

---

- Finally, we assign the weights to each neighboring polygon. The argument `style` can take on a number of character values: W=row standardized, B=binary, C=globally standardized. With
`zero.policy=TRUE` we insert zero into the weights matrix where there is no connection
```{r echo=TRUE, include=TRUE,eval=TRUE}
w.rook.l <- nb2listw(w.rook, style="B", zero.policy=TRUE)
w.rook.l$weights[1] # Check the weight of the first polygon's three neighbors
```

```{r echo=TRUE, include=TRUE,eval=TRUE}
w.rook.m <- nb2mat(w.rook, style="B", zero.policy = TRUE) #  spatial weights matrix
w.rook.m
```
---

- We now plot the neighbour relationship based on rook move adjacency

```{r echo=TRUE, eval=FALSE}
# Compute coordinates at centroids of each canton
coords <- coordinates(lux)

# Plot
par(mai=c(0,0,0,0))
plot(lux, col='white', border='blue')
plot(w.rook, coords, col='red', lwd=2, add=TRUE)
```

`r include_fig("Rplot.jpeg",width="45%")`
---
# Intrinsic Conditional Autoregressive (ICAR) model `r Cite(bibfile, "Besag74")`

.panelset[
.panel[.panel-name[General definition]

$$\mathbf{u} \sim \hbox{ICAR}(\mathbf{W},\sigma^2_u)$$

with

`r vspace("20px")` 
- $\mathbf{W}$ matrix defining the neighbours (weights)
- $\sigma^2_u$ conditional variance parameter of $\mathbf{U}$

$$u_i \mid u_{j \;\; j\ne i} \sim \hbox{Normal}\left(\frac{\sum_{j} W_{ij} u_j}{\sum_{j} W_{ij}}, \frac{\sigma^2_u}{\sum_{j}  W_{ij}}\right)$$
]

.panel[.panel-name[Common definition]

$$\mathbf{u} \sim \hbox{ICAR}(\mathbf{W},\sigma^2_u)$$

Let $\partial_i =$ set of areas adjacent to $i$, $w_{ij}$  = 1 for $j \in \partial_i$, 0 otherwise
$$u_i \mid u_{j \;\; j\ne i} \sim \hbox{Normal}\left(\frac{\sum_{j \in \partial_i} u_j}{n_i}, \frac{\sigma^2_u}{n_i}\right)$$

`r vspace("20px")`

- $u_i$ is smoothed towards mean risk in a set of neighbouring areas
- Conditional variance inversely proportional to the number of neighbours (so more neighbours, less variability)

]

.panel[.panel-name[Remarks]
- ICAR model is improper: the overall mean of the $\bm{u}$ is not defined. So an additional constraints needs to be imposed:
.red[**sum-to-zero constraint**:]  $\sum_i u_i  = 0$

`r vspace("20px")`  

- The parameter $\sigma^2_u$ represents the .red[**conditional**] variance of the random effects (and not the marginal one) and its magnitude determines the amount of spatial variation

`r vspace("20px")`

- No closed-form expression available for the .red[**marginal**] between-area variance of the spatial effects 
  &rarr; estimate marginal spatial variance empirically
$$s^2_{\text{u.marginal}} = \sum_i (u_i - \overline{u})^2 / (N-1)$$
]
]

---

# Combining ICAR with unstructured random effects

- ICAR model makes a strong spatial assumption; it cannot take a limiting form that allows non-spatial variability

- Besag, York and Mollie (BYM) recommended combining the ICAR prior and the standard normal prior to allow for both     
  - spatially unstructured latent covariates $\bm{v}$ modelled as iid
  &rarr; global smoothing
  - spatially correlated latent covariates $\bm{u}$ modelled as ICAR
  &rarr; local smoothing
  
.panelset[
.panel[.panel-name[BYM]
\begin{align*}
y_i &\sim \text{Poisson}(\lambda_i = \rho_i E_i)\\
\eta_i &= \log \rho_i = b_0 + v_i + u_i\\
v_i &\sim \text{Normal}(0, \sigma^2_v)\\
\mathbf{u} &\sim \hbox{ICAR}(\mathbf{W},\sigma^2_u)
\end{align*}

- Need to specify hyperprior distributions for:

- $\sigma^2_v$ (between-area unstructured marginal variance), e.g. $1/\sigma^2_v \sim \text{Gamma}(1,0.001)$
- $\sigma^2_u$ (between-area spatial conditional variance), e.g. $1/\sigma^2_u \sim \text{Gamma}(1,0.001)$
- $b_0$ (mean log relative risk), e.g. $b_0 \sim \text{Normal}(0,0.0001)$ 
]

.panel[.panel-name[BYM2]

\begin{align*}
y_i &\sim \text{Poisson}(\lambda_i = \rho_i E_i)\\
\eta_i &= \log \rho_i = b_0 + b_i\\
\boldsymbol{b} &= \frac{1}{\sqrt{\tau_b}}(\sqrt{1-\phi}\boldsymbol{v}_{*} + \sqrt{\phi}\boldsymbol{u}_{*})
\end{align*}

where $\boldsymbol{v}_{*}$ and $\boldsymbol{u}_{*}$ are standardised versions of $\bm{u}$ and $\bm{v}$. 

- Need to specify hyperprior distributions for:

- $\phi$ which is the weight of the spatially structured residual
- $\tau_b$ which is the marginal variance of the random effect 
]
]

---

# Priors for BYM2
    
Under the BYM2 specification the hyperparameters $\tau_b$ and $\phi$ are modelled using .red[**Penalised Complexity** (PC) priors] `r Cite(bibfile,"10.1214/16-STS576")`

- Regularise inference while not forcing too strong information

- Penalise departure from a "base" model (e.g.,  typically characterised by a fixed value of the relevant parameter)

- Prior tends to favour the base model &rarr; need fairly strong evidence to move away from it

- Distance between the **base** model $\color{red}g(\xi)$ and an **alternative**, more complex model $\color{blue}f(\xi)$ is measured by the Kullback-Leibler divergence (kld)

  
.blue[
$$d(f,g) = \sqrt{2\kld(f,g)} \qquad {\style{font-family:inherit; font-size: 105%; color: black;}{\text{with}}} \qquad \kld(f,g) = \int f(\xi)\log\left(\frac{f(\xi)}{g(\xi)}\right)d\xi$$
]

--

- And penalization from the base model is done at a constant rate on the distance by assigning an exponential distribution to $d$:

.blue[   
$$p(d)=\lambda\exp(-\lambda d)\sim \dexp(\lambda)$$
]

- PC prior defined using probability statements on the model parameters (in the appropriate scale) to determine the value of $\lambda$ using "reasonable" information

- For PC priors, see section 5.4 of the book **Bayesian inference with INLA** (https://becarioprecario.bitbucket.io/inla-gitbook/index.html) and sections 4.3:4.4 of the book **Geospatial Health Data: Modeling and Visualization with R-INLA and Shiny** (https://www.paulamoraga.com/book-geospatial/index.html)

---

# Priors for BYM2

Using probability statements we can define the PC priors for the two hyperparameters as:
`r vspace("-10px")`
.pull-left[
.content-box-beamer[
### Prior on $\tau_b$

$$P((1/\sqrt{\tau_b})>U_1) = \alpha_1$$

which can be interpreted as .blue[*the probability that the standard deviation of the random effect is larger than*] $\class{blue}{U_1}$ .blue[*is equal to*] $\class{blue}{\alpha_1}$
]
]

.pull-right[
.content-box-beamer[
### Prior on $\phi$

$$P(\phi < U_2) = \alpha_2$$

which can be interpreted as .blue[*the probability that the spatial random effect explains less than*] $\class{blue}{U_2}$ .blue[*of the total variability is equal to*] $\class{blue}{\alpha_2}$
]
]

---
count: false
# Priors for BYM2

Using probability statements we can define the PC priors for the two hyperparameters as:
`r vspace("-10px")`
.pull-left[
.content-box-beamer[
### Prior on $\tau_b$

$$P((1/\sqrt{\tau_b})>U_1) = \alpha_1$$

which can be interpreted as .blue[*the probability that the standard deviation of the random effect is larger than*] $\class{blue}{U_1}$ .blue[*is equal to*] $\class{blue}{\alpha_1}$
]
]

.pull-right[
.content-box-beamer[
### Prior on $\phi$

$$P(\phi < U_2) = \alpha_2$$

which can be interpreted as .blue[*the probability that the spatial random effect explains less than*] $\class{blue}{U_2}$ .blue[*of the total variability is equal to*] $\class{blue}{\alpha_2}$
]
]

`r vspace("5px")`

where $\lambda = \frac{-\log(\alpha_k)}{U_k}$



- We need to define $U_1, U_2$ and $\alpha_1, \alpha_2$ and following `r Citet(bibfile, "10.1214/16-STS576")`:
`r vspace("10px")`

--

  - A marginal sd not too large (e.g. 0.5);

--

  - $\alpha_1=0.01$ (we want to allow for a small probability)

--

  - $\alpha_2=2/3$ (we expect a higher probability that the variability to be explained by the spatial random effect is lower than 50%)

--

- Then 

    1\. Assuming $U_1=0.5/0.31$ translates into $P(\sigma_{\tau_b}>1.62) = 0.01$, using the rule of thumb in `r Citet(bibfile, "10.1214/16-STS576")`
    
    2\. Assuming $U_2=0.5$ we get $P(\phi < 0.5) = 2/3$

---

# Poisson model with BYM random effects 

- Choice of the adjacency matrix (neighbours): 2 areas are neighbours if they share a common border

  &rarr; Adjacency matrix implemented in INLA     

- An area cannot be specified as its own neighbour

- Adjacency matrix must be symmetric

--

- $\text{RR}_i = \exp(b_0 + b_i)$: RR in area $i$ relative to the age/sex structure (used to estimate the $E_i$)

- $\hbox{residual RR}_i = \exp(b_i)$: residual RR in area $i$ relative to the region average after adjusting for the overall risk

--

- $\sigma^2_b$ reflects the marginal variability of the REs 

- $\phi$ represents the weight of the spatial structure

---

name: Example
  
`r vspace("250px")`

.myblue[.center[.huge[
**Example: Suicides in London**]]]

---

# Suicides in Greater London, M+F, 1989-1993, Boroughs

- 32 boroughs in Greater London

- Interest: mapping the RR in each borough

- Methods with no spatial structure: SMR, non spatial smoothing

- Spatial smoothing using the BYM model

\begin{align*}
y_i & \sim  \hbox{Poisson}(\rho_i E_i)\\
\log \rho_i  & =  b_0 + b_i\\
v_i &\sim  \hbox{Normal}(0, \sigma^2_v)\\
\bm{u} & \sim  \hbox{ICAR}(\mathbf{W}, \sigma^2_u)
\end{align*}

- Data: $\bm{y}$ and $\bm{E}$
- Priors: $\sigma^2_v$, $\sigma^2_u$, $b_0$
- Parameters of interest: 
  - residual RR $(\hbox{resRR}_i=\exp(b_i))$
  - marginal variance $(1/ \tau_b)$
  - percent of total variation in the log RR due to spatial effects $(\phi)$
  
---

# Adjacency matrix in INLA
    
- It is possible to produces a graph from a shapefile

`r vspace("20px")`

- Upload the shapefile using `sf` package

```{r read_shp, echo=TRUE, include=TRUE,eval=FALSE}
library(sf)
london.gen = read_sf("LDNSuicides.shp")
london.gen$ID = seq(1,32)

```

```{r read_shp1, echo=TRUE, include=FALSE,eval=TRUE}
library(sf)
london.gen = read_sf("~/Dropbox/TEACHING/YEAR_2023/Advanced_Analytics_2023/Material/Datasets/LDN/LDNSuicides.shp")
london.gen$ID = seq(1,32)
```

--

- Use `poly2nb` and `nb2INLA` from the `spdep` package to transform the shapefile into adjacency matrix

```{r spdep, echo=TRUE, include=TRUE,eval=FALSE}
library(spdep)
nb2INLA("LDN.graph",poly2nb(london.gen))
LDN.adj = paste(getwd(),"/LDN.graph",sep="")
```
  
--

- Now `LDN.graph` has been saved in the working directory and can be called when specifying the BYM model (see later)

---

# Spatial distributions for area level data in INLA

We introduce here the specification of the `ICAR` and `BYM2` models in `INLA`, which are done through `f()`:

.panelset[
.panel[.panel-name[ICAR in `INLA`]
```{r xx, echo=TRUE, eval=FALSE}
formula.ICAR = y ~ f(ID, model="besag", graph=LDN.adj)	
```
             
`r vspace("20px")`

- `ID` is the area identifier

`r vspace("20px")`

- `graph=LDN.adj` identifies the adjacency structure constructed as seen before

`r vspace("20px")`

- `model=besag` specifies the intrinsic conditional autoregressive structure as described before

On the example:

```{r suicides-besag, echo=TRUE, eval=FALSE}
formula = y ~ 1 + f(ID, model="besag",graph=LDN.adj, 
                    hyper=list(
                      prec=list(
                        prior="loggamma",param=c(1,0.0005))))
```
]

.panel[.panel-name[BYM2 in `INLA`]
```{r xxx, echo=TRUE, eval=FALSE}
formula.BYM2 = y ~ f(ID, model="bym2", graph=LDN.adj)	
```

`r vspace("20px")`

- `ID` is the area identifier

`r vspace("20px")`

- `graph=LDN.adj` identifies the adjacency structure constructed as seen before

`r vspace("20px")`

- `model=BYM2` specifies the combination of the intrinsic conditional autoregressive structure and unstructured random effect as described before

On the example:

```{r suicides-bym, echo=TRUE, eval=FALSE}
formula = y ~ 1 + f(ID, model="bym2",graph="LDN.graph", 
        hyper=list(prec = list(
        prior = "pc.prec",
        param = c(0.5 / 0.31, 0.01)),
        phi = list(
        prior = "pc",
        param = c(0.5, 2 / 3))))
```
]
]

---

# Running the model in `INLA`

```{r code_suicides, echo=TRUE, eval=TRUE, include=FALSE}
load("~/Dropbox/TEACHING/YEAR_2023/Advanced_Analytics_2023/Material/Datasets/LDN/LondonSuicides.RData")
library(INLA)
datasuicides = tibble(y=y,E=E, ID=seq(1,32))
Nareas = 32
formula = y ~ 1 + f(ID, model="bym2",graph="~/Dropbox/TEACHING/YEAR_2023/Advanced_Analytics_2023/Material/Datasets/LDN/LDN.graph", 
        hyper=list(prec = list(
        prior = "pc.prec",
        param = c(0.5 / 0.31, 0.01)),
        phi = list(
        prior = "pc",
        param = c(0.5, 2 / 3))))

mod.suicides = inla(formula,family="poisson",
                       E=E,data=datasuicides,
                       control.compute=list(dic=TRUE))
```

To run the model in INLA
```{r running, echo=TRUE, eval=FALSE}
mod.suicides = inla(formula,family="poisson",
                       data=data.suicides,E=E,
                       control.compute=list(dic=TRUE, waic=TRUE))
```

`R-INLA` estimates the parameters $\bm \theta = \{b_0, \bm{b}, \bm{u}\}$ and the hyper-parameters  $\bm\psi=\{\tau_{b}, \phi\}$.

---

# How to get information from random effects
 
- The random effect are obtained through 

```{r raneff, echo=TRUE, eval=FALSE, include=TRUE}
mod.suicides$summary.random$ID

```

```{r raneff1, echo=FALSE, eval=TRUE, include=TRUE}
head(mod.suicides$summary.random$ID)

```

which is a matrix formed by $2n$ rows: 

  - $1:n$ rows include information on the area specific residuals $b_i$
  - $n+1:2n$ rows are the spatially structured residual $u_i$

---

# How to get information from random effects
 
- All these parameters are on the logarithmic scale; to transform the **marginal** back to the natural scale:
.pull-left[
```{r trans, echo=TRUE, eval=TRUE}
b = mod.suicides$marginals.random$ID[1:Nareas]
```
this returns a list with `Nareas` number of elements, each representing the posterior marginal of $b_i$ for that area
]

.pull-right[
```{r fig2.1, echo=FALSE, out.width="50%", opts=list(width="50%")}
plot(b[[1]],type="l", cex.lab=1.5)
```
]

--
`r vspace("20px")`

- Then we can get the posterior mean and 95% credible intervals:

.pull-left[
```{r trans1, echo=TRUE, eval=TRUE, include=TRUE}
zeta = lapply(b,function(x) inla.emarginal(exp,x))
zeta_CI = lapply(b,function(x) 
inla.qmarginal(c(0.025,0.975),
    inla.tmarginal(exp,x)))
```
]

.pull-right[
```{r trans1-CI, echo=FALSE, eval=TRUE, include=FALSE}
#CI <- tibble(mean=unlist(zeta),CI2.5=unlist(zeta_CI)[seq(1,64,2)],CI97.5=unlist(zeta_CI)[seq(2,64,2)], ID=datasuicides$ID)
#ggplot(CI, aes(x=ID,y=mean)) + geom_point() + 
#  geom_hline(yintercept=1,linetype="dashed") + 
#  geom_errorbar(aes(ymin=CI2.5, ymax=CI97.5), width=.1) 
```

`r vspace("-150px")`

`r include_fig("trans1-plot-1.png",width="50%",title="")`
]

---

# Identification of spatial patterns
 
- What is the sensitivity vs specificity of smoothed RR?
  - Ability to detect true patterns (sensitivity)
  - Ability to discard false patterns (specificity)

`r vspace("10px")`

- Detection of increased/decreased RR 

  &rarr; Posterior probabilities that the residual RR is above/below 1 `r Cite(bibfile,"Richardson:2004")`

`r vspace("10px")`

- Area with an increased risk
\begin{align*}
\hbox{P(resRR}_i>1)>0.8 & \Leftrightarrow \hbox{P}(e^{(u_i+v_i)}>1)>0.8\\
& \Leftrightarrow  \hbox{P}(u_i+v_i>0)>0.8
\end{align*}
  
- Area with a decreased risk
\begin{align*}
\hbox{P(resRR}_i<1)>0.8 & \Leftrightarrow  \hbox{P}(e^{(u_i+v_i)}>1)<0.2\\
& \Leftrightarrow  \hbox{P}(u_i+v_i>0)<0.2
\end{align*}
     
---
    
# Posterior probability in INLA
     
- Remember the parametrisation $\zeta = \exp{(b_i)}$
      
- We can visualize $p(\zeta_i>1\mid \bm y)=p(b_i>0\mid \bm y)$ using the built-in function `inla.pmarginal`:
```{r postprob, echo=TRUE,eval=TRUE}
a = 0
prob.b = lapply(b, function(x) {1 - inla.pmarginal(a, x)})
```

--

- Create an object with all the info to map
```{r map-prep,echo=TRUE}
RR_BYM = tibble(zeta=unlist(zeta),prob=unlist(prob.b), ID=seq(1,32))
out_map = left_join(london.gen,datasuicides, by="ID") %>% left_join(., RR_BYM, by="ID")
out_map$pp_breaks = cut(out_map$prob, 
                           breaks = c(0, c(0.2, 0.8), 
                                      1), include.lowest = T)
```

---

#...and then create some maps

.pull-left[
### Map of posterior mean of $b_i$
```{r map-post-mean,echo=TRUE}
ggplot() + geom_sf(data = out_map, 
                   aes(fill = zeta)) + 
            scale_fill_viridis_c()
```
]

.pull-right[
### Map of posterior probability of $b_i>0$
```{r map-post-p,echo=TRUE}
ggplot() + geom_sf(data = out_map, 
           aes(fill = pp_breaks)) + 
  scale_fill_manual(values = c("blue","orange","red"))
```
]

---

# Output from different models

.panelset[
.panel[.panel-name[Comparing maps]     
.pull-left[
- **SMR** non smoothed RR
                 
- **HET** non spatially smoothed residual RR: $\exp(v)$
                   
- **CAR** spatially smoothed residual RR: $\exp(u)$
                   
- **BYM** spatially and non spatially smoothed residual RR: $\exp(b)=\exp(u+v)$
]
.pull-right[
`r include_fig("Lungmales_4maps.jpg",width="90%",title="")`
]
]

.panel[.panel-name[Shrinkage]
.pull-left[  
`r include_fig("Lungmales_shrinkage.jpg",width="90%",title="")`
]

.pull-right[
- Shrinkage towards the mean due to the **borrowing of strength**
]
]

.panel[.panel-name[Interpretation]

- Smoothed relative risks are more stable (precise than observed)

&rarr; geographical patterns of risk are easier to detect using smoothed maps

`r vspace("10px")`

- Smoothed relative risks have higher specificity:
  - Possible "false positive" values shrunk towards mean
  - But in danger of over-smoothing (false negatives)

`r vspace("10px")`

- Visual impact of maps can be very dependent on the choice of colours and cut-points used to shade each region

&rarr; Care must be taken not to over-interpret any patterns identified

]
]
---

name: Poisson-regression
  
`r vspace("250px")`

.myblue[.center[.huge[
**Ecological regression with spatial random effects (Generalized linear mixed-effect models)**]]]

---
# Disease Mapping vs Ecological Regression
       
## Disease mapping studies
       
- Focus is on description
- Level of inference is at the aggregate (small area) level
       
      
## Ecological correlation studies
       
- Focus is on **explanation**
  
  - Used for investigating specific exposure-disease hypotheses at small-area scale

  - Poisson regression can be used to model relationship between any area-level exposure measure and incidence/prevalence of disease

  - Such area-level exposure measures include average annual pollution level, proportion of population who smoke, proportion of population living with x km of a landfill site, etc.
 
---

# Poisson regression with random effects 

Straightforward extension of disease mapping model:

.content-box-beamer[
### Ecological regression with BYM structure
  
\begin{align*}
\hbox{y}_i & \sim  \hbox{Poisson}(E_i \rho_i); \;\;\; i=1,...,N\\
\log \rho_i & =  b_0 + \class{red}{\beta_1 x_i} + u_i + v_i\\
\text{residual RR}_i &= \exp(b_i) = \exp(u_i + v_i)\\
\boldsymbol{b} &= \frac{1}{\sqrt{\tau_b}}(\sqrt{1-\phi}\boldsymbol{v}_{*} + \sqrt{\phi} \boldsymbol{u}_{*})\\ 
v_i &\sim \text{Normal}(0, \sigma^2_v) \;\;\; \mathbf{u} \sim \hbox{ICAR}(\mathbf{W},\sigma^2_u)
\end{align*}
]

`r vspace("20px")`

where
 
- $O_i$ and $E_i$: Observed and expected nb of cases in each area $i$
- $\lambda_i$: unknown RR
- $x$  area-level covariate of interest
- $\beta_1$: parameter associated with the covariate
- $\bm v_{*}$: standardised version of unstructured random effects, i.i.d.
- $\bm u_{*}$: standardised version of random effects with spatial structure, conditional distribution


---
  
# Interpretation of the parameters

- $\exp(\beta_1)$ is the change in risk associated with a unit
   change in exposure $x$
   
`r vspace("30px")`
   
- $b_i$ is the  random effect in area $i$

`r vspace("30px")`

- $\exp(b_i)$ is the residual or adjusted relative risk of disease
   in area $i$ .blue[after accounting for the effects of measured covariates and the
   overall mean risk]

`r vspace("30px")`

- The variance of the random effects reflects the amount of overdispersion
   in the data (total residual variance = Poisson variance + random effects variance)
 
---
# Poisson regression with random effects - INLA code

- Continuous covariate
```{r ecoreg, echo=TRUE, eval=FALSE}
formula.ecoreg.inla = y ~ 1 + x +
        f(id,model="bym", graph=graph,                 
          hyper=list(prec.spatial=list(
                prior="loggamma",param=c(0.01,0.01))))
```

  - Categorical covariate
```{r ecoreg2, echo=TRUE, eval=FALSE}
formula.ecoreg.inla = y ~ 1 + cut(x,breaks=c(0,7,10,24),
                           include.lowest=TRUE) +
                           f(id,model="bym", graph=graph,   
                             hyper=list(prec.spatial=list(
                             prior="loggamma",param=c(0.01,0.01))))
```

---

# Comparison between disease mapping and ecological regression

`r vspace("-40px")`

`r include_fig("LipCancer.png", width="50%",title="")`

`r vspace("-40px")`

- Less extreme values when covariates are included

&rarr; part of the spatial variability is explained by the covariates
---
# Poisson regression with random effects

.content-box-beamer[

### Extension to several variables

\begin{align*}
\hbox{y}_i & \sim  \hbox{Poisson}(E_i \rho_i); \;\;\; i=1,...,N\\
\log \rho_i & =  b_0 + \beta_1 x_{1i} +\beta_2 x_{2i} + b_i\\
& ...
\end{align*}
]

`r vspace("10px")`

- $\exp(\beta_1)$ is the relative risk of disease/death associated with a unit
   increase in exposure $x_1$, after adjustment for $x_2$
   
`r vspace("10px")`

- $\exp(\beta_2)$ is the relative risk of disease/death associated with a unit
   increase in exposure $x_2$, after adjustment for $x_1$

`r vspace("10px")`

- $\exp(b_i)$ is the residual or adjusted relative risk of disease/death
   in area $i$ after accounting for the effects of measured covariates and the overall mean risk
 
---
     
 # Summary
  
- Hierarchical models allow "borrowing of strength" across units
 
  - posterior distribution of $\rho_i$ for each unit borrows
   strength from the likelihood contributions for
   **all** the units, via their joint influence on the posterior
   estimates of the unknown hyper-parameters
 
`r vspace("10px")`
 
- Judgements of exchangeability need careful assessment
 
  - units suspected a priori to be systematically different might be modelled by including relevant covariates so that residual variability more plausibly reflects exchangeability
  - subgroups of prior interest should be considered separately

`r vspace("10px")`

- Mapping geographical variations in disease risk is an important epidemiological technique for
   suggesting aetiological hypotheses

`r vspace("10px")`

- When combined with data on geographical variations in exposure, disease mapping techniques can be used to investigate and quantify **ecological** associations between disease risk and potential exposures

---
# A few notes on ecological bias and atomistic fallacy

- In the today's sessions, we worked with aggregated data.

- Aggregation has implications for the type of inference that are possible.

- Ecological inference is the process where aggregated data are used to infer individual level relationships. Reasons:

  - individual data are not available for confidentiality reasons;
  - individual data are not reliable or too expensive to be collected;

- .red[Ecological (or aggregation) bias] can occur. It is the difference between the estimates of relationships obtained using grouped data and those estimates obtained using individual data (e.g. the association observed at the area level do not hold for the individuals within areas).

- Ecological bias can manifest itself in a variety of ways and results in an information loss (e.g. it can be due to a model specification bias that arises because a nonlinear risk model changes its form under aggregation). Researchers should specify the conditions under which the estimates are reasonable.

-  The converse, using individual level estimates uncritically to infer group level relationships (ignoring the possibility of group level or contextual effects) is called as .red[atomistic or individualistic fallacy].


---

# References

```{r refs, echo=FALSE, results="asis"}
PrintBibliography(bibfile,.opts=list(max.names=3))
```
