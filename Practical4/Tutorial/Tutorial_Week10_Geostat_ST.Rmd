---
title: Modelling point-level space-time data - An application using ozone concentrations in New York 
author: "Bayesian modelling for spatial and spatio-temporal data"
date: 'Week 10'
output: html_document
fontsize: 11pt
keep_tex: yes
fig_caption: yes
bibliography: biblio.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.width=7, fig.height=4, fig.align = 'center')
```


In this tutorial we use a dataset that comprises daily maximum
8-hour average ground level ozone (O$_3$, ppb) concentrations for the period July 1 and August 31 in 2006, measured at 28 monitoring sites in the state of New York, USA. 
The stations are part of the Environmental Protection Agency (EPA) monitoring network.
Ozone  occurs naturally in the upper atmosphere and protects the Earth from the sun's rays. However, at ground level it can be harmful for population health, as it can lead to adverse respiratory effects. Ozone is most likely to reach worrisome levels on hot sunny days in urban environments (even so it can still reach high levels during colder months).  
Ozone is one of the “criteria pollutants” regularly monitored by the US EPA.

The dataset used for this tutorial is included in the packages `spBayes` and `spTimer`.
Today we will use the package `spTimer` by @Bakar2015 to model ozone concentrations in New York state. This package is exclusively devoted
to fitting and prediction for point-referenced spatio-temporal data.
The paper by @Bakar2015 uses this dataset for demonstration. Here we follow their analysis.


The data available are as follows:

* `s.index`: index of the monitoring station in the NY state

* `Longitude` and `Latitude`: spatial coordinates of the monitoring stations

* `Year`, `Month` and `Day`: temporal coordinates of the measurement

* `o8hrmax`: daily 8-hour maximum average ozone concentrations (parts per billion) 

* `cMAXTMP`: maximum temperature (in degree Celsius) 

* `WDSP`: wind speed (knots), 

* `RH`: percentage average relative humidity 

Of the 1,736 possible observations, i.e., n=28 locations times T=62 daily `o8hrmax` measurements, 114 are missing. 


We use `o8hrmax` concentrations as outcome and `cMAXTMP`, `WDSP`, and `RH` as predictors.


# Before starting the tutorial

* Create a separate directory in your home directory to save your files created during this tutorial.

* Copy all the files from the blackboard to your directory (created just above). 

* If not installed yet, then install the R packages required for this tutorial
```{r eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE}
install.packages(c("lubridate","spTimer","dplyr" ,"coda", "ggmcmc","mcmcplots","GGally","leaflet","mvtsplot", "maps","MBA", "fields","colorspace","corrr","knitr", "kableExtra"), type = "both",
dependencies = TRUE, repos = c(CRAN = "http://cran.r-project.org"))
```

* Load needed libraries:
```{r echo=TRUE, eval = TRUE, message=FALSE}
library(lubridate)    # tools to work with date-time data
library(dplyr)        # tools data manipulations
library(spTimer)      # package for point-referenced spatio-temporal data
library(coda)         # tools for convergence diagnostics 
#library(ggmcmc)       # tools for MCMC diagnostics using ggplot
# library(mcmcplots)  # tolls for MCMC diagnostics
library(GGally)       # tools for plots (extend functionality of
                      # ggplot2)
library(mapview)      # interactive maps
library(corrr)        # tools for exploring correlations 
library(mvtsplot)     # function for plotting multivariate time series 
                      # data
library(maps)         # display of maps
library(MBA)          # functions to interpolate irregularly and 
                      # regularly spaced data 
library(fields)       # tools for Spatial Data
library(colorspace)   # toolbox for colors or color palettes

# For tables in RMarkdown
library(knitr)
library(kableExtra)

```


# The New York dataset: visualization, manipulation and explorative analysis

The data are obtained from 28 monitoring sites, between July 1 and August 31 in 2006. 

* Load the data in `R` 

```{r eval=TRUE, echo=TRUE, message=FALSE}
data(NYdata)
```


* Now, we print the data, formatting these in a table.

```{r eval=TRUE, echo=TRUE, message=FALSE}
kable(head(NYdata), 
      caption = "The first 6 rows of New York dataset") %>% 
kable_styling(bootstrap_options = "striped", full_width = F, position = "center")

# Print the data
NYdata[1:6,] %>%
  kbl(caption = "The first 6 rows of New York dataset") %>%
  kable_classic(full_width = F, html_font = "Cambria")

```


* We provide a map of the monitoring station using `mapview` package.  Here we plot the longitude and latitude using the World Geographic System 1984 (WGS84) projection, which is referenced as European Petroleum Survey Group (EPSG) 4326 (note that, EPSG 4326 is the projection used by web maps such as Google Maps)

```{r eval=TRUE, echo=TRUE, message=FALSE, fig.cap = "Map of the monitoring stations in New York State"}
stations <- cbind(unique(NYdata[,1]), unique(NYdata[,2:3]))

# set the map projection to a common projection standard such as WGS84 via the argument crs = 4326
mapview(stations, xcol = "Longitude", ycol = "Latitude", crs = 4269, grid = FALSE)
```


* We create a variable `date` using the package `lubridate`, which is part of the core `tidyverse`.

```{r eval=TRUE, echo=TRUE, message=FALSE}
NYdata <- NYdata %>%
  mutate(date = make_date(Year, Month, Day))


```


* We now plot the concentrations of ozone for each monitoring station using the package `mvtsplot`, which allows the visualization of Multivariate time Series (Link: http://www.biostat.jhsph.edu/~rpeng/RR/mvtsplot/). To be able to use it, we need to convert the data from long to wide format.

```{r eval=TRUE, echo=TRUE, message=FALSE}
# select ozone data
O3 <- NYdata %>% select(s.index, o8hrmax, date)
dim(O3) #1736    3

O3_wide = O3 %>% 
  spread(s.index, o8hrmax)
dim(O3_wide) #62 29

O3_wide <- O3_wide[,-1] # remove date
O3_wide <- data.matrix(O3_wide)
dim(O3_wide)

colnames(O3_wide) <- unique(O3[,1])

```

And now plot the ozone concentrations for the 28 monitoring stations

```{r eval=TRUE, echo=TRUE, fig.cap = "Daily ozone levels for 28 monitoring stations, Jul 1– Aug 31, 2006"}

# Daily ozone levels for 28 monitoring stations, Jul 1– Aug 31, 2006.
mvtsplot(O3_wide, group = NULL, xtime = NULL, norm = c("global"),
         levels = 3, smooth.df = NULL, margin = TRUE, sort =NULL,
         main = "", palette = "PRGn", rowstat = "median", xlim,
         bottom.ylim = NULL, right.xlim=NULL, gcol = 3)

```
In the plot we use as color `PRGn` (default) from the `RColorBrewer` palettes. Here green indicates high values and purple indicates low values. Missing data are denoted by the color white. The bottom panel shows the overall median.  Finally, on the right hand side panel, we can see the boxplots of the data in each time series.


* Moreover, we can check the basic statistics for ozone concentrations and make the histogram 

```{r eval=TRUE, echo=TRUE, message=FALSE, fig.cap = "Histgram of ozone concentrations"}
summary(NYdata$o8hrmax)
hist(NYdata$o8hrmax)

```


* We can visualize the relationships between the data using `GGally`, as we did in week 8. 

```{r eval=TRUE, echo=TRUE, message=FALSE, fig.cap = "Figure 4. Plot of the correlation between variables in analysis", fig.height=6, fig.width = 11}
ggpairs(NYdata[,7:10]) # print correlations between variables

```

* We print the table of the correlations between ozone and the three predictors using the package `corrr`:

```{r eval=TRUE, echo=TRUE, message=FALSE}
tab_cor = NYdata %>%
  select(o8hrmax, cMAXTMP, WDSP, RH) %>%
  correlate() %>%
  shave(upper = TRUE) %>%
  fashion(decimals = 2, na_print = "—") 

tab_cor

```


* Now, we prepare data for spatial prediction and forecast (cross-validation)

```{r eval=TRUE, echo=TRUE, message=FALSE}
# define prediction sites for cross-validation (i.e. validation sites)
s <- c(8,11,12,14,18,21,24,28) # 8 stations

# deselected sites for predictions from dataset (training sites)
DataFit <- spT.subset(data=NYdata, var.name=c("s.index"), s=s, reverse=TRUE) 
# Dim = 1240 (20stations*62days) * 11
# Note: spT.subset selects a subset of the dataset using the site numbers

# subset records without two days for forecast (30 and 31 August)
DataFit <- subset(DataFit, with(DataFit, !(Day %in% c(30, 31) & Month == 8))) # Dim = 1200 (20stations*60days) * 11

# select data for prediction (validation set)
DataValPred <- spT.subset(data=NYdata, var.name=c("s.index"), s=s) 
# dim = 496 (8stations*62days) * 11

# remove days for forecast from validation set
DataValPred <- subset(DataValPred, with(DataValPred, !(Day %in% c(30, 31) & Month == 8))) # dim = 480 (8station*60days) * 11

# subset sites for forecast (validation set)
DataValFore <- spT.subset(data=NYdata, var.name=c("s.index"), s=c(8,11,12,14,18,21,24,28)) # dim = 496 (8stations*62days) * 11

# subset days for forecast within validation set (30 and 31 August for validation sites)
DataValFore <- subset(DataValFore, with(DataValFore, (Day %in% c(30, 31) & Month == 8))) # dim = 16 (8station*2days) * 11

```


* Plot the training and validation set (using `maps` package)

```{r eval=TRUE, echo=TRUE, message=FALSE, fig.cap = "Map of the training and validation sites"}
coords <- as.matrix(unique(cbind(DataFit[,2:3])))
pred.coords <- as.matrix(unique(cbind(DataValPred[,2:3])))

maps::map(database="state",regions="new york")
points(coords, pch=19, col=3)
points(pred.coords, pch=3, col=4)
legend(x=-79.5,y=41.5,col=c(3,4),pch=c(19,3),cex=0.8,legend=c("Training (Fitted) sites","Validation sites"))

```

## Geostatistical spatio-temporal model

We now implement the spatio-temporal linear regression model for ozone concentrations using `spTimer`. Let: 

* $\boldsymbol{Y}_t =(Y(\mathbf{s}_1,t), \dots, Y(\mathbf{s}_n,t))'$ be the observed data at location $\mathbf{s}$ in day $t$

* $\boldsymbol{O}_t =(O(\mathbf{s}_1,t), \dots, O(\mathbf{s}_n,t))'$ be the true value corresponding to $\boldsymbol{Y}_t$.

We use a hierarchical structure and we fit the following Bayesian model, with nugget effect model together with an independent Gaussian Process (GP) model at each time point:

\begin{equation*}
\begin{split}
 %Y(\mathbf{s}_i,t) &= \boldsymbol{X}'(\mathbf{s}_i,t) \boldsymbol{\beta} + \boldsymbol{\eta}(\mathbf{s}_i,t)+\boldsymbol{\epsilon}(\mathbf{s}_i,t)
 \boldsymbol{Y}_t &= \boldsymbol{O}_t +\boldsymbol{\epsilon}_t\\
  \boldsymbol{O}_t &= \boldsymbol{X}_t \boldsymbol{\beta} + \boldsymbol{\eta}_t
\end{split}
\end{equation*}

where:

+ $\boldsymbol{X}_t$ are the covariate values and $\boldsymbol{\beta}$ are the regression coefficients

+ $\boldsymbol{\eta}_t=(\eta(\mathbf{s}_1,t), \dots, \eta(\mathbf{s}_n,t))'$ are the spatio-temporal random effects, assumed to follow $N(\mathbf{0}, \Sigma_{\eta})$  independently in time, where $\Sigma_{\eta}=\sigma_{\eta}^{2} S_{\eta}$, here $\sigma_{\eta}^2$ is the site invariant spatial variance  and $S_{\eta}$ is the spatial correlation matrix.

+ $\boldsymbol{\epsilon}_t=(\epsilon(\mathbf{s}_1,t), \dots, \epsilon(\mathbf{s}_n,t))'$ is the nugget effect or the pure error term, independent in space and time.

```{r eval=TRUE, echo=TRUE, message=FALSE}
set.seed(11)
post.gp <- spT.Gibbs(formula=o8hrmax ~ cMAXTMP+WDSP+RH, 
                     data=DataFit, model="GP", 
                     coords=~Longitude+Latitude, 
                     scale.transform="SQRT",
        spatial.decay=spT.decay(distribution=Gamm(2,1),tuning=0.1),
        nItr = 15000, nBurn = 5000,report = 1,
        distance.method = "geodetic:km", cov.fnc = "exponential")

```

* Perform diagnostic

```{r eval=TRUE, echo=TRUE, message=FALSE, fig.height=10, fig.width = 10}
# plot(post.gp)

# with coda
autocorr.plot(as.mcmc(post.gp))
plot(as.mcmc(post.gp), auto.layout=TRUE, density=FALSE)

# with mcmcplots
# mcmcplot(post.gp)
```

```{r eval=TRUE, echo=TRUE, message=FALSE, fig.height=7, fig.width = 5}
# with ggmcmc
ggsamples <- ggs(as.mcmc(post.gp))
ggsamples %>% filter(Parameter == c("cMAXTMP","WDSP","RH")) %>% 
  ggs_density() + theme_bw()

```

* Obtain the parameter estimates from the MCMC samples

```{r eval=TRUE, echo=TRUE, message=FALSE}
print(post.gp)
summary(post.gp)

```
The parameter estimates show that the predictors, except relative humidity, have an impact on ozone concentrations, since the 95% credible intervals of the regression coefficients for wind and max temperature do not contain zero. 
The posterior estimate of the spatial decay parameter $\phi$ is approximately 0.007 implies an effective range of $\sim$ 428 kilometers (obtained as $3/\phi$).


* Obtain the PMCC

```{r eval=TRUE, echo=TRUE, message=FALSE}
post.gp$PMCC

```


### Spatial prediction for the GP model

```{r eval=TRUE, echo=TRUE, message=FALSE}
set.seed(11)
pred.gp <- predict(post.gp, newdata=DataValPred, 
                   newcoords=~Longitude+Latitude)

print(pred.gp)
names(pred.gp)
```

### Validation criteria

```{r eval=TRUE, echo=TRUE, message=FALSE}
spT.validation(DataValPred$o8hrmax,c(pred.gp$Median))  

```


### Temporal prediction 
Here the forecast for two-step ahead (i.e., in day 61 and 62) in the unobserved locations using output from spT.Gibbs

```{r eval=TRUE, echo=TRUE, message=FALSE}
set.seed(11)
fore.gp <- predict(post.gp, newdata=DataValFore,
                   newcoords=~Longitude+Latitude, 
                   type="temporal", foreStep=2)
print(fore.gp)

```


* Forecast validations

```{r eval=TRUE, echo=TRUE, message=FALSE}
spT.validation(DataValFore$o8hrmax,c(fore.gp$Median)) 

# Inspect the two forecast (posterior median) for the validation sites
fore.gp$Median

```


## Prediction on the grid

* We now perform prediction on a grid to obtain a continuous surface of ozone concentrations. To do so, we read in `NYgrid`, which contains a total of 6200 rows for 62 days of observations for 10x10 = 100 grid
points. 
Then we re-run the GP model for all the points in the dataset (i.e. `NYdata`) and make prediction on the grid.

```{r eval=TRUE, echo=TRUE, message=FALSE}
data(NYgrid)
set.seed(11)

# GP regression 
# (for demonstration, we us here a low number of iterations)
post.gp2 <- spT.Gibbs(formula=o8hrmax ~cMAXTMP+WDSP+RH,   
        data=NYdata, model="GP", 
        coords=~Longitude+Latitude, nItr=5000, nBurn=1000,
        scale.transform="SQRT",
        spatial.decay=spT.decay(distribution=Gamm(2,1),tuning=0.1))

# Prediction
set.seed(11)
grid.pred <- predict(post.gp2, newdata=NYgrid,
                     newcoords=~Longitude+Latitude)

```

* Finally, we plot the spatial predictions (code by the authors is provided https://github.com/cran/spTimer/blob/master/demo/nyExample.R)

```{r eval=TRUE, echo=TRUE, message=FALSE}
# this function is created by spTimer's authors and 
# it used to delete values outside NY
fnc.delete.map.XYZ <- function(xyz){
	x<-xyz$x; y<-xyz$y; z<-xyz$z
	xy <- expand.grid(x, y)
	eus <- (map.where(database="state", x=xy[,1], y=xy[,2]))
	dummy <- rep(0, length(xy[,1]))
	eastUS <- NULL
	eastUS <- data.frame(lon=xy[,1],lat=xy[,2],state=eus,dummy=dummy)
	eastUS[!is.na(eastUS[,3]),4]<-1
	eastUS[eastUS[,3]=="pennsylvania" & !is.na(eastUS[,3]),4]<-0
	eastUS[eastUS[,3]=="new jersey" & !is.na(eastUS[,3]),4]<-0
	eastUS[eastUS[,3]=="connecticut" & !is.na(eastUS[,3]),4]<-0
	eastUS[eastUS[,3]=="massachusetts:main" & !is.na(eastUS[,3]),4]<-0
	eastUS[eastUS[,3]=="new hampshire" & !is.na(eastUS[,3]),4]<-0
	eastUS[eastUS[,3]=="vermont" & !is.na(eastUS[,3]),4]<-0
	a <- eastUS[, 4]
	z <- as.vector(xyz$z)
	z[!a] <- NA
	z <- matrix(z, nrow = length(xyz$x))
      xyz$z <- z
      xyz
}

```

```{r eval=TRUE, echo=TRUE, message=FALSE}
coords <- unique(NYdata[,c("Longitude","Latitude")])
grid.coords <- unique(NYgrid[,c("Longitude","Latitude")]) 
true.val <- matrix(NYdata$o8hrmax,62,28) # 62 time points, 28 stations
grid.val <- matrix(grid.pred$Median,62,dim(grid.coords)[[1]])
grid.sd <- matrix(grid.pred$SD,62,dim(grid.coords)[[1]])

surfplot<-function(day=60, val, ...) # three dots are called ellipsis
{
    z <- val
	surf <- cbind(grid.coords, z[day,])
	surf <- mba.surf(surf,200,200)$xyz # from MBA package
	surf <- fnc.delete.map.XYZ(xyz=surf)
	image.plot(surf, xlab="Longitude",ylab="Latitude",axes=F, ...) # from fields package
	contour(surf,nlevels=10,lty=3,add=T)
	map(database="state",regions="new york",add=T) # add contour NY from maps package
	axis(1);axis(2)
}

```


* Now we use the functions written by the authors to obtain the spatially interpolated plots of the daily maximum 8-hour ozone concentration levels (posterior median) and its standard deviation. Here we plot them for the 29 August, 2006 (i.e. day 60)  
 
```{r eval=TRUE, echo=TRUE, message=FALSE, fig.cap="Spatial interpolation of the daily maximum 8-hour ozone concentrations"}

# prediction for day 60
# Actual observations are superimposed
day <- 60
surfplot(day, val=grid.val, col = rainbow_hcl(100, start = 200, end = 0))
text(coords,labels=round(true.val[day,],1), cex=0.8,col=1)

```

```{r eval=TRUE, echo=TRUE, message=FALSE, fig.cap="Standard deviation of ozone concentrations"}
# Standard deviation for day 60
# Actual location of the monitoring stations are superimposed
day <- 60
surfplot(day, val=grid.sd, col = diverge_hcl(100, h = c(246, 40), c = 96, l = c(65, 90)))
points(coords,pch=19,cex=1,col=1)  

# Note that the hcl function from colorspace package creates a vector of R colours with the given hue, chroma and luminance values. Here in diverge_hcl function: h refers to the hue value, while c and l refer to the chroma value and luminance in the HCL color description
                                 
```

# References