---
title: "Practical 3b - Linear Regression: Frequentist *vs* Bayesian analysis"
author: "Bayesian modelling for Spatial and Spatio-Temporal data"
bibliography: [biblio.bib, packages.bib]
nocite: '@*' # include entries in the bibliography or references that aren't actually cited in the text
output: 
  html_document:
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

\pagenumbering{gobble} 
\pagenumbering{arabic} 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.align = "center", class.source='klippy')
```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('top', 'right'),color = 'darkred',
               tooltip_message = 'Click to copy', tooltip_success = 'Done')
```

In this practical we will develop a multiple linear regression model on real data and we will compare Frequentist and Bayesian methods. 

The aims of this practical are to get a general understanding of how to:

(i) Perform a simple Bayesian analysis of real data using the `R` package `INLA`, and compare this with a Frequentist analysis;

(ii) Download and process data from `Fingertips` data tool, which is a major public repository of population and public health indicators for England;

(iii) Cite automatically `R` packages in R Markdown 


In detail, `Fingertips`, is a large repository of indicators for public health data. 
Data are structured by thematic profiles, which cover a wide range of health related topics. Here we investigate the relationship between socio-economic deprivation and life-expectancy at birth.
We will use the package `fingertipsR` in `R` to obtain the data.


In addition to `fingertipsR` and `INLA`, we use the following packages:

+ `dplyr`, which includes tools for data manipulation;
+ `tidyr`, which includes tools to create tidy data;
+ `stringr`, which provide a set of functions designed to work with strings; 
+ `jtools`, which includes tools for summarizing and visualizing regression models;
+ `ggplot2`, which is an excellent package for data visualization. It implements the *grammar of graphics*, proposing a scheme for data visualization which breaks up graphs into semantic components such as scales and layers.


# 1. Install and load R-packages

* To start with, install the packages `fingertipsR` 

```{r eval=FALSE, message=FALSE}
# Enable repository from ropensci
options(repos = c(
  ropensci = 'https://ropensci.r-universe.dev',
  CRAN = 'https://cloud.r-project.org'))

# Download and install fingertipsR in R
install.packages('fingertipsR')
# or use
# remotes::install_github("rOpenSci/fingertipsR", build_vignettes = TRUE, dependencies = "suggests")
```


* Then load the packages needed for this lab

```{r libs, eval=TRUE, message=FALSE}
# Load the package fingertipsR
library("fingertipsR")
library("INLA")

# Load the other packages 
packages = c("ggplot2", "dplyr", "tidyr", "stringr", "jtools")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
```


# 2. How to cite R packages?

* To cite a R package, we can use the command `citation` and this will return the reference, including the bib format
```{r}
citation("ggplot2")
```

* However, if we want to city all the packages used in this lab automatically, we can proceed by setting a chunk of code for automatic citations of the R packages. This is obtained via the function `knitr::write_bib()`, which generates citation entries to a file and adds keys automatically

```{r }
# Automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), packages
), 'packages.bib')
```
Here, `.packages()` returns the names of all packages loaded in the current R session. This makes sure all packages being used will have their citation entries written to the .bib file (for details you can check the online freely available book @xie2020r).


# 3. Get and process the data 

- We download the data using `fingertipsR` package. For details about the package, you can check the vignettes

```{r eval = FALSE}
browseVignettes("fingertipsR")
```


- We start by examining which profiles and domains are available in the `fingertipsR` package, then we download data from the *Public Health Outcomes Framework* profile, finally we select the  indicator on *Healthy Life Expectancy at Birth*

```{r eval = TRUE, results="hide"}
profiles = profiles()

profiles = profiles[grepl("Public Health Outcomes Framework", profiles$ProfileName),]

head(profiles)
```

- To check which indicators constitute a domain, we can use the `indicators()` function 

```{r eval = TRUE, results="hide"}
profid = 19 # 19 is the ProfileID of the "Public Health Outcomes Framework"
inds = indicators(ProfileID = profid)

print(inds[grepl("Healthy", inds$IndicatorName), c("IndicatorID", "IndicatorName")])
```

- Now, we extract the life expectancy at birth indicator using the `fingertips_data()` function. It corresponds to the IndicatorID equal to 90362.  
Unless specified with an `AreaTypeID` code, it downloads data for Upper Tier Local Authorities (AreaTypeID equal to 102) if available (also described as County and Unitary Authorities).

Life expectancy at birth will be our response variable. Then, we will use the level of deprivation and sex as explanatory variables.

```{r echo=TRUE, eval=TRUE, results='hide'}
# Extract the data using the fingertips_data() function
# ?fingertips_data
LifeExp = fingertips_data(IndicatorID = 90362, AreaTypeID = 102) 
head(LifeExp)

LifeExp = LifeExp %>%
select(IndicatorID, IndicatorName, AreaCode, AreaName, AreaType,
Sex, Age, Timeperiod, Value) %>%
mutate(IndicatorName =
str_trunc(as.character(IndicatorName), width = 20, "right"),
AreaName = str_trunc(as.character(AreaName), width = 20, "right"))#%>%
#head()

unique(LifeExp$Timeperiod)
unique(LifeExp$AreaType)
```

- Note that to find available areas and relevant AreaTypeID codes, we can use the `area_types()` function

```{r echo=TRUE, eval=FALSE}
areas = area_types()
areas %>%
  select(AreaTypeID, AreaTypeName) %>%
  distinct() 
```

- We recover the index of deprivation for the year 2015 and join it with LifeExp data.  The Index of Multiple Deprivation 2015 (IMD 2015) is an overall measure of multiple deprivation experienced by people living in an area (for details see https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/465791/English_Indices_of_Deprivation_2015_-_Statistical_Release.pdf).

```{r eval=TRUE, results='hide'}
# To check what AreaTypeIDs are available
# indicator_areatypes() 

Dep15 = deprivation_decile(AreaTypeID = 102, Year = 2015)
head(Dep15)

# Join data
# Restrict to relevant geography (Upper Tier Local
# Authority) and time (years 2014-16)
LifeExp = LifeExp %>%
filter(AreaType == "Counties & UAs (pre Apr 2019)" & Timeperiod == "2014 - 16") %>%
left_join(., Dep15) # merge in deprivation data

head(LifeExp)
```

- Produce a summary of the data to check completeness

```{r eval=FALSE}
summary(LifeExp)
```

we can see the the Value of life expectancy is missing for 4 observations. For the purpose of this practical, drop the rows with missing observations and call the new data set as LifeExp.nomis

```{r eval=TRUE}
#Remove rows that contains NA's
LifeExp.nomis = LifeExp %>% drop_na()
```


- Plot the life expectancy *vs* the deprivation score by sex using `ggplot2`. In particular, inside `aes()` (aesthetic), we specify the response variable with `y = Value`, the continuous explanatory variable with `x = IMDscore` and the categorical explanatory variable with `colour = Sex`. The opacity of the `geom` (geometric object; here `geom_point`) is governed by values of `alpha`. It ranges from 0 to 1, with lower values corresponding to more transparent colors.
Note that we use `+` to connect the elements of the graph.

```{r eval=FALSE, fig.cap ="Life expectancy at birth by index of multiple deprivation, England 2014-16"}

LifeExp.nomis %>%
  ggplot(aes(x = IMDscore, y = Value, colour = Sex)) +
  geom_point(alpha = 0.2) +
  scale_x_continuous("IMD score") +
  scale_y_continuous("Life expectancy")
```

- The IMD score is available also in deciles. It has been processed so Decile 1 represents the most deprived 10\% (or Decile) of small areas in England, and Decile 10 represents the least deprived 10\%.
Note however there is no definitive threshold above which an area is described as deprived; the Indices of Deprivation are a continuous scale of deprivation. 

Here we further manipulate the data, inspecting the difference between the most and least deprived areas by sex.

```{r, fic.cap="Life expectancy at birth between the least and most deprived areas of England for both males and females"}

# Filter the data
df.plot = LifeExp.nomis %>% 
  filter(decile == 1 | decile == 10)

# Create new variable that identifies the most and least deprived areas
df.plot = df.plot %>%  # mutate() adds new variables and preserves existing ones
  mutate(IMDstatus = case_when(
    decile == 1 ~ "Most deprived",
    decile == 10 ~ "Least deprived"
  ))

# Grouped barplot using ggplot2 
ggplot(df.plot,   
       aes(x = IMDstatus,
           y = Value,
           fill = Sex)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  scale_fill_brewer(palette="Blues")+
   theme_minimal()
```
Note that the default behavior of `geom_bar()` is to count the rows for each x value. If we explicitly say `stat = "identity"` in `geom_bar()`, we are telling ggplot2 to skip the aggregation and that we will provide the y values.


- What you conclude from these preliminary exploratory analyses?


# 4. Models

We specify now the multiple linear regression model, taking the value of life expectancy at birth as response variable, and  deprivation score and sex as explanatory variables.

Let $y_i$ be the life expectancy in unit $i$ for $i=1, \dots, n$ (i.e. response variable) and $x_{ji}$ be the $j$-th covariate available in unit $i$, i.e. multiple deprivation score and sex. The model to be fitted is the following:

$$y_i = \beta_0 + \sum_{j=1}^{2} \beta_j x_{ji} + \epsilon_{i}$$

where:

- $\beta_0$ is the intercept 

- $\beta_j$ for $j=1,2$ are the coefficients associated with the explanatory variables, i.e. $\beta_1$ is the parameter for the effect of the multiple deprivation score `IMDscore` and $\beta_2$ is the parameter for the effect of `Sex`.
The latter is categorical variable, therefore it has a baseline level in `R`. The parameter associated with the categorical variable estimates the difference in the response variable in a group different from the baseline. Since the letter *f* precedes *m* in the alphabet, `R` will take Female as the baseline level.

- $\epsilon_i$ for $i=1,\dots,n$ is an error term Gaussian distributed with mean zero and variance $\sigma^{2}_{\epsilon}$.


## 4.1 Frequentist model

- We fit the standard linear model in `R`. First define the formula, and call is as `my.formula`. Then, fit the model (call is as `m1`) and obtain and check the estimated coefficients. Finally, get the 95\% confidence interval (95\% CI) using the function `sumn` from the package `jtools` (i.e. `summ(m1, confint = TRUE, digits = 3)`)

```{r eval=TRUE, echo=FALSE, results='hide'}
my.formula = Value ~ IMDscore + Sex       # formula

m1 = lm(formula=my.formula, data=LifeExp.nomis) # fit a linear model

round(coef(summary(m1)),3)                 # estimated coefficients

summ(m1, confint = TRUE, digits = 3)       # 95%CI
```

* How would you interpret these results?


## 4.2 Bayesian model 

- Now, we fit a Bayesian linear regression model using `INLA` with the default priors. Here, the main function to run a model is  `inla()`, which takes care of all model fitting. 
By default:

(i) the intercept has a Gaussian prior with mean and precision equal to zero.

(ii) the coefficients of the fixed effects also have a Gaussian prior with zero mean and precision equal to 0.001.

(iii) the prior on the precision of the error term is a Gamma distribution with parameters 1 and 0.00005 (shape and rate, respectively).

* Fit the model using the function `inla` and call the result as `m2`. Then, obtain a summary of the model using the function `summary()`, which displays summary statistics on the posterior marginals of the model latent effects, hyperparameters and other quantities of interest.

```{r eval=TRUE, echo=FALSE, results='hide'}
# Fit linear regression model using INLA
m2 = inla(formula=my.formula, data = LifeExp)

summary(m2)
```


* Now, obtain the posterior summary of the fixed effect and hyperparameters

```{r eval=TRUE, echo=FALSE, results='hide'}
round(m2$summary.fixed, 3)     # Post marginal fixed effects

round(m2$summary.hyperpar, 3)  # Post marginal hyperparameters
```

* How you can see from the summary, by default the posterior summaries of the precision is outputted. However, we are often interested in the posterior mean of the standard deviation. Obtain its estimate using the function `inla.emarginal` as we did in Practical 3a

```{r eval=TRUE, echo=FALSE, results='hide'}
## Posterior mean of the standard deviation
inla.emarginal(fun=function(x) 1/sqrt(x), marginal = m2$marginals.hyperpar$`Precision for the Gaussian observations`) 

# or We use [[1]] instead of the long name
# inla.emarginal(fun=function(x) 1/sqrt(x), marginal = m2$marginals.hyperpar[[1]]) 
```

* Now, plot the posterior distribution of the measurement error standard deviation 

```{r eval=FALSE, echo=FALSE, results='hide'}
post.sigma = inla.tmarginal(function(x) 1/sqrt(x), 
  		m2$marginals.hyperpar[[1]]) 

plot(inla.smarginal(post.sigma),type="l",xlab="",
ylab="",main=expression(paste("Post. marg. of ", sigma)))
```

* Explore the names of the fixed effects

```{r eval=TRUE}
# Check the fixed effect names
names(m2$marginals.fixed) 
```

* Plot the marginal posterior distributions of $\beta_0$, $\beta_1$ and $\beta_2$, tacking advantage of the function `inla.smarginal`

```{r eval=FALSE, echo=FALSE, results='hide'}
post.beta0 = m2$marginals.fixed[[1]]
post.beta1 = m2$marginals.fixed$IMDscore
post.beta2 = m2$marginals.fixed$SexMale

# Plot the intercept
plot(inla.smarginal(post.beta0),type="l",xlab="",ylab="",
     main=expression(paste("Post. marg. of ", beta[0])))

# Plot beta1
plot(inla.smarginal(post.beta1),type="l",xlab="",ylab="",
     main=expression(paste("Post. marg. of ", beta[1])))

# Plot beta2
plot(inla.smarginal(post.beta2),type="l",xlab="",ylab="",
     main=expression(paste("Post. marg. of ", beta[2])))

```

# 5. Compare the INLA model output to the `lm` output

Now we compare the estimates obtained from the Bayesian and the frequentist model

```{r eval=TRUE, fig.cap =""}
cbind(m2$summary.fixed[,1:2],summary(m1)$coef[,1:2])
```
Here, the first two columns are the posterior means and SDs from the INLA model, while the third and fourth are the corresponding values from the frequentist model. 

What do you conclude? 



# 6. Compute the fitted values

* To compute the fitted value, we need to compute the posterior means of the linear predictors. This is performed by including `control.predictor=list(compute=TRUE)` within the `inla` function.
Modify the model `m2` to include it, and call the new model as `m3`.

```{r eval=TRUE, echo=FALSE, results='hide'}
m3 = inla(formula=my.formula, control.predictor=list(compute=TRUE),            data = LifeExp.nomis)
```

* Obtain the fitted values from the Bayesian model and compare the posterior means to the fitted values obtained from the `lm()` function:

```{r eval=TRUE, echo=TRUE, results='hide'}
ypostmean = m3$summary.linear.predictor[,1]

plot(ypostmean, as.vector(m1$fitted.values), xlab="INLA posterior fitted means", ylab="LM fitted values")
abline(0,1)

```

# References