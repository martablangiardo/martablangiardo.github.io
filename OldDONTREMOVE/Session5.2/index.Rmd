---
title: "Session 5.2: Missing data inputation"
params: 
   conference: "Bayesian modelling for Spatial and Spatio-temporal data"
   location: "Imperial College"
   date: ""
   short_title: "MSc in Epidemiology"
output:    
  xaringan::moon_reader: 
    includes: 
       in_header: "../assets/latex_macros.html" 
       # This line adds a logo based on the format selected in the file 'assets/include_logo.html'
       # NB: the actual options (eg placement of the logo and actual logo file) can be changed there
       after_body: "../assets/insert-logo.html"
    seal: false
    yolo: no
    lib_dir: libs
    nature:
      beforeInit: ["https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: yes
      countIncrementalSlides: no
      ratio: '16:9'
      titleSlideClass:
      - center
      - middle
    self_contained: false 
    css:
    - "../assets/beamer.css"
---

```{r global_options, echo = FALSE, include = FALSE}
options(width = 999)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      cache = FALSE, tidy = FALSE, size = "small")
```
```{r echo=F,message=FALSE,warning=FALSE,comment=NA}
# Sources the R file with all the relevant setup and commands
source("../assets/setup.R")
library(INLA)

# Stuff from 'xaringanExtra' (https://pkg.garrickadenbuie.com/xaringanExtra)
# This allows the use of panels (from 'xaringanExtra')
xaringanExtra::use_panelset()
# This allows to copy code from the slides directly
#xaringanExtra::use_clipboard()
# This freezes the frame for when there's a gif included
#xaringanExtra::use_freezeframe()

# Defines the path to the file with the .bib entries (in case there are references)
bibfile=ReadBib("~/Dropbox/Bayes_Spatial_2023/Material/Biblio.bib",check = FALSE)
#bibfile=ReadBib("~/Dropbox/Lavori condivisi/2015_Book/ShortCourse/VIBASS/Biblio.bib",check = FALSE)

```

class: title-slide

# `r rmarkdown::metadata$title``r vspace("10px")` `r rmarkdown::metadata$subtitle`

## `r rmarkdown::metadata$author`

### `r rmarkdown::metadata$institute`    

### `r rmarkdown::metadata$params$conference`, `r rmarkdown::metadata$params$location` 

<!-- Can also separate the various components of the extra argument 'params', eg as in 
### `r paste(rmarkdown::metadata$params, collapse=", ")`
-->

`r ifelse(is.null(rmarkdown::metadata$params$date),format(Sys.Date(),"%e %B %Y"),rmarkdown::metadata$params$date)`

---

layout: true  

.my-footer[ 
.alignleft[ 
&nbsp; &copy; Marta Blangiardo | Monica Pirani 
]
.aligncenter[
`r rmarkdown::metadata$params$short_title` 
]
.alignright[
`r rmarkdown::metadata$params$conference`, `r short_date` 
]
] 

```{css,echo=FALSE, eval=FALSE}
.red {
  color: red;
}
.blue {
  color: 0.14 0.34 0.55;
}

.content-box-blue { background-color: #F0F8FF; }

}
```
<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>


---

# Learning Objectives

After this session you should be able to:

`r vspace("10px")`

- Appreciate the importance of thinking about why data are
missing, and stating your modelling assumptions

`r vspace("10px")`

- Understand the disadvantages of complete case analysis

`r vspace("10px")`

- Learn about how Bayesian methods can be used as  ‘statistically principled’ for handling missing data

`r vspace("10px")`

- Be able to run the above models in R-INLA

`r vspace("10px")`


The topics treated in this lecture are covered in Chapter 12 of `r Citet(bibfile, "gomez2020bayesian")`.

---

# Why we care about missing data

- Missing data are common!

- Usually inadequately handled in both observational and
experimental research

`r vspace("10px")`

- For example, `r Citet(bibfile, "wood2004missing")` reviewed 71 recently published BMJ, JAMA, Lancet and NEJM papers

  - 89% had partly missing outcome data
  
  - In 37 trials with repeated outcome measures, 46% performed complete case analysis
  
  - Only 21% reported sensitivity analysis

`r vspace("20px")`

- `r Citet(bibfile, "sterne2009multiple")` reviewed articles using Multiple Imputation in BMJ, JAMA, Lancet and NEJM from 2002 to 2007

  - 59 articles found, with use doubling over 6 year period
  
  - However, the reporting was almost always inadequate

---

# Outline 

1\. [How do missing data arise?](#how)

`r vspace("30px")`

2\. [Example: children height and weight](#example)

`r vspace("30px")`

3\. [Bayesian imputation](#model)

`r vspace("30px")`

4\. [Extending the model](#extending)

`r vspace("30px")`

---

name: how

`r vspace("250px")`

.myblue[.center[.huge[
**How do missing data arise?**]]]


---

# How do missing data arise?

`r include_fig("Missing_DAG.png", width="80%")`

---

# Different types of missing data: MCAR

- There are three types of missing data, depending on why the missingness arise. Let's define $m_i$ as the variable indicating if the $i-th$ observation is missing

$$m_i \sim \text{Bernoulli}(p_i)$$

1\. .red[Missing completely at random] (MCAR) occurs when the missing data are independent from the observed or unobserved data: 

$$\text{logit}(p_i) = \theta_0$$
This means that the missing values can be ignored and the analysis can be conducted as usual. 

---

# Different types of missing data: MAR and MNAR

2\. .red[Missing at random] (MAR) occurs when the missing data depends ONLY on the observed data: 

$$\text{logit}(p_i) = \theta_0 + \bf{x}_i \mathbf{\theta}_1$$
 In this case, this can be introduced into the model so that missing observations are imputed as part of the model fitting.
 
--

`r vspace("40px")`

3\. .red[Missing non at random] (MNAR) occurs when the missing data depends on both the observed and missing data: 

$$\text{logit}(p_i) = \theta_0 + \bf{x}_i \mathbf{\theta}_1 + \lambda y_i$$

This scenario is difficult to tackle since there is no information about the missingness mechanism and the missing data.

---

# Missing response or missing covariates

- Additionally, it is crucial to distinguish between missing values .blue[in the response] and .blue[in the covariates]. 

`r vspace("30px")`

- When the missingness is in the response (and it is MCAR or MAR), these can naturally be predicted as the distribution of the response values is determined by the statistical model to be fit (posterior predictive distribution in the Bayesian approach)

`r vspace("30px")`

- Missingness in the covariats requires additional steps:
`r vspace("10px")`
  - a model needs to be specified on the covariate (imputation model) if the missingness mechanism is MCAR or MAR
`r vspace("10px")`
  - an additional model of missingness needs to be specified if the mechanism is MNAR
`r vspace("10px")`  
  - Here we will consider only missing values in the response
`r vspace("10px")`  
  - `R-INLA` reguires a certain degree of complexity to deal with missing values in covariates, if you are interested in learning more look at `r Citet(bibfile, "gomez2022missing")`
  

---

name: example

`r vspace("250px")`

.myblue[.center[.huge[
**Example: height and weight of children**]]]


---

# Example: height and weight of children

- Information of 10,030 children measured within the Fifth Dutch Growth Study 2009 `r Citep(bibfile, "schonbeck2013world")`

`r vspace("20px")`

- Data available from the `fdgs` dataset in the `library(mice)` `r Citep(bibfile, "van2011mice")`

`r vspace("20px")`

```{r eval=TRUE, include=FALSE, echo=FALSE}
library(mice)
data(fdgs)
```

```{r tableAlt}
library(kableExtra)
df<- data.frame(Variable=colnames(fdgs), Description=c("Child ID", "Region (5 levels)", "Age (year)", "Sex", "Height (cm)", "Weight (kg)", "Re-scaled height (as a Z-score)", "Re-scaled weight (as a Z-score)"), Missing=c(0,0,0,0,23,20,23,20))
df %>%  kbl(col.names = colnames(df)) %>%  kable_classic(full_width=F,  position = "center")
```
---
# Summarising the data

- The data can be summarised using

```{r eval=TRUE, echo=TRUE}
summary(fdgs)
```

- Note that several variables in the dataset have missing observations. In particular, height `(hgt)` and weight `(wgt)`, which are common variables used as response or predictors in models

---

# Subsetting the data

- In order to provide a smaller dataset to speed up computations, only the children with missing values (in height and weight) and another 1000 ones taken at random will be used in the analysis

```{r eval=TRUE, include=TRUE, echo=TRUE}
# Subsect 1, observations with NA's
subset1 <- which(is.na(fdgs$wgt) | is.na(fdgs$hgt))

#Subset 2, random sample of 1000 individuals
set.seed(1)
subset2 <- sample((1:nrow(fdgs))[-subset1], 1000)
# Subset 1 + subset 2
fdgs.sub <- fdgs[c(subset1, subset2), ]
summary(fdgs.sub)
```
---
name: model

`r vspace("250px")`

.myblue[.center[.huge[
**Bayesian imputation**]]]


---

# Model specification


- We first predict weight as a function of age and sex. We specify:
$$wgt_i \sim \text{Normal}(\alpha+\beta_1 sex_i + \beta_2 age_i, \sigma^2)$$
- where `wgt` is missing we will have `NA` in the corresponding vector, e.g.
```{r eval=TRUE, include=TRUE, echo=TRUE}
fdgs.sub$wgt[1:10]
```
 
- Remember the posterior predictive distribution (presented in lecture 2.2):

	$$p(\mathbf{y}^*|\mathbf{y}) = \int p(y^*|\theta)p(\theta|\mathbf{y})d\theta$$

  - here $\mathbf{y}^*$ identifies the missing values, while $\mathbf{y}$ is the set of observed values for `wgt` 

---

# Running the model in `R-INLA`

```{r eval=TRUE, include=TRUE, echo=TRUE}
library("INLA")
wgt.inla <- inla(wgt ~ age + sex, data = fdgs.sub,
control.predictor = list(compute = TRUE), control.compute=list(return.marginals.predictor=TRUE))
wgt.inla$summary.fixed
wgt.inla$summary.hyperpar

```

- Note that we need to include `control.predictor=list(compute = TRUE)` so `INLA` can estimate the predictive distribution for the missing observations, while `control.compute=list(return.marginals.predictor=TRUE)` tells inla that we want to access the entire posterior distribution of the prediction (rather than only the summary)

---

# Getting the posterior prediction

We now subset the children indexes with missing values so we can report their predictive distributions:

```{r eval=TRUE, include=TRUE, echo=TRUE}
wgt.na <- which(is.na(fdgs.sub$wgt))
rownames(fdgs.sub)[wgt.na]
# Obtain the predictive distribution
wgt.inla$summary.fitted.values[wgt.na, c("mean", "sd")][1:5,]
```

Remember that you can also access the marginal posterior distributions (rather than the summary) using `wgt.inla$marginals.fitted.values`
---

# Imputing `hgt` using the same approach

- Similarly, a model can be fit to explain height based on age and sex and to compute the predictive distribution of the missing observations:

```{r eval=TRUE, include=TRUE, echo=TRUE}
hgt.inla <- inla(hgt ~ age + sex, data = fdgs.sub,
control.predictor = list(compute = TRUE),
control.compute = list(return.marginals.predictor=TRUE))
hgt.inla$summary.fixed
hgt.inla$summary.hyperpar

```

---

# Imputing `hgt` using the same approach

.pull-left[
`r vspace("24px")`
- We can obtain the predictions using


```{r eval=TRUE, include=TRUE, echo=TRUE}
hgt.na <- which(is.na(fdgs.sub$hgt))
hgt.inla$summary.fitted.values[hgt.na, c("mean", "sd")][1:10,]
```
]

.pull-right[
- We can plot the entire posterior distributions for each child with:
```{r eval=TRUE, echo=TRUE, out.width="50%", opts=list(width="80%")}
# First child with missing value
plot(hgt.inla$marginals.fitted.values[[hgt.na[1]]], type="l")
```
]

---



name: extending

`r vspace("250px")`

.myblue[.center[.huge[
**Extending the model**]]]


---


# Joint model of height and weight

- The two previous models consider height and weight separately, but it is clear that there is a high correlation between height and weight, which is caused by the age and sex of the child. 

```{r eval=TRUE, include=TRUE}
cor(hgt.inla$summary.fitted.values$mean,wgt.inla$summary.fitted.values$mean)
```
- We can build a joint model for height and weight to exploit a correlated effect between the coefficients of age in both models.

\begin{align*}
hgt_i &= \alpha_h + \beta_{h1} sex_i + \beta_{h2} age_i + \epsilon_{1i}\\
wgt_i &= \alpha_w + \beta_{w1} sex_i + \beta_{w2} age_i + \epsilon_{2i}\\
\end{align*}

with 
  - $\alpha_h,\alpha_w$ model intercepts
  - $\beta_{h1},\beta_{w1}$ the effect of sex
  - $\beta_{h2},\beta_{w2}$ the effect of age
  - $\mathbf{\epsilon_{1}},\mathbf{\epsilon}_{2}$ the error terms (note that this specification is equivalent to the one above for the separate models)
  
---

# Joint model of height and weight: prior

- The vectors $(\mathbf{\beta}_{1h}, \mathbf{\beta}_{1w})$ and $(\mathbf{\beta}_{2h}, \mathbf{\beta}_{2w})$ are modeled using a multivariate Gaussian distribution with mean 0 and covariance matrix with $1/\tau_{hj}$ and $1/\tau_{wj}$ as variances and $\rho_j  / \sqrt{(\tau_{jh} \tau_{jw})}$ as the covariance where $\rho_j$ is the correlation parameter.

- First, the bivariate response variable needs to be put in a two-column matrix given that the model will be made of two data distributions

```{r eval=TRUE, include=TRUE, echo=TRUE}
n <- nrow(fdgs.sub)
y <- matrix(NA, nrow = 2 * n, ncol = 2)
y[1:n, 1] <- fdgs.sub$hgt
y[n + 1:n, 2] <- fdgs.sub$wgt
```

- Similarly, as we have two intercepts, we need to define these explicitly as covariates with all values equal to one:
```{r eval=TRUE, include=TRUE, echo=TRUE}
I <- matrix(NA, nrow = 2 * n, ncol = 2)
I[1:n, 1] <- 1
I[n + 1:n, 2] <- 1
```

---

# Correlated effects

- Now we need to define the correlated effects. We will use the random effect specification similar to what we saw with the hierarchical models (`iid`), but modified to have the two coefficients as correlated `f(...,model=iid2d)`. 

- In order to do so we need to modify the variables `age` and `sex` as they will be passed to the model as weights of the latent random effects `iid2d` specification. We need them to be twice as long to match the dimension of the response:

```{r eval=TRUE, include=TRUE, echo=TRUE}
age.joint <- rep(fdgs.sub$age, 2)
sex.joint <- rep(fdgs.sub$sex, 2)
```

- Finally we need two index vectors to indicate which coefficient to use from the `iid2d` model is required. These indexes will be 1 for the first half of observations (to indicate that the coefficient is $\beta_h$ and 2 for the second half (to indicate that the coefficient is $\beta_w$).

```{r eval=TRUE, include=TRUE, echo=TRUE}
idx.age = rep(1:2, each = n)
idx.sex = rep(1:2, each = n)
```

---

# Model fitting

```{r eval=TRUE}
set.seed(5678)
```

The model is fit and summarized as seen below
```{r eval=TRUE, include=TRUE, echo=TRUE}
# Model formula
joint.f <- y ~ -1 + I + f(idx.sex, sex, model="iid2d", n=2) + f(idx.age, age, model = "iid2d", n = 2) 
# Model fit
fdgs.joint <- inla(joint.f, 
  data = list(y = y, I = I, sex = sex.joint, age = age.joint, idx.age = idx.age, idx.sex= idx.sex),
  family = rep("gaussian", 2),
  control.predictor = list(compute = TRUE))
# Summary fixed (intercept)
fdgs.joint$summary.fixed
```

---

# Hyperparameters and variable effects

- The hyperparameters can be obtained through

```{r eval=TRUE, include=TRUE, echo=TRUE}
fdgs.joint$summary.hyperpar
```

- While the coefficients for `age` and `sex` are part of the random effects of the model:
.pull-left[
```{r eval=TRUE, include=TRUE, echo=TRUE}
#Sex
fdgs.joint$summary.random$idx.sex
```
]

.pull-right[
`r vspace("-23px")`
```{r eval=TRUE, include=TRUE, echo=TRUE}
#Age
fdgs.joint$summary.random$idx.age
```
]
---

# Estimates of missing values

- Finally to access the predicted values for the children with missing data we need to remember that we now have the response `y` stacked (first height, then weight)

- As height is the first variable we can use `hgt.na` to get to the indexes of the children with missing data

- For weight we need to use `wgt.na` and add `n` to each index, as this is the total number of observations, so the data for weight will start on the index 1044

```{r eval=TRUE, echo=TRUE}
joint.wgt.na = wgt.na+n
```

```{r eval=FALSE, include=TRUE, echo=TRUE}
#Height
fdgs.joint$summary.fitted.values[hgt.na, c("mean", "sd")][1:10,]
#Weight
fdgs.joint$summary.fitted.values[joint.wgt.na, c("mean", "sd")][1:10,]
```
---

# Comparing the results of the joint and separate models

.pull-left[

.red[Weight]

```{r eval=TRUE}
plot(wgt.inla$summary.fitted.values[wgt.na, "mean"], fdgs.joint$summary.fitted.values[joint.wgt.na, "mean"], main="", xlab="weight only model",ylab="joint model")
abline(0,1)
```
]

.pull-right[

.red[Height]

```{r eval=TRUE}
plot(hgt.inla$summary.fitted.values[hgt.na, "mean"], fdgs.joint$summary.fitted.values[hgt.na, "mean"], main="", xlab="height only model",ylab="joint model")
abline(0,1)
```
]
---

# References

```{r refs, echo=FALSE, results="asis"}
PrintBibliography(bibfile,.opts=list(max.names=3))
```
