---
title: "Practical 2 - Conjugacy, prediction and Monte Carlo simulation"
author: "Spatial and Spatio-Temporal Bayesian Models with `R-INLA`"
output: 
  html_document:
    css: practical.css
    toc: true
    toc_float: true
---

\pagenumbering{gobble} 
\pagenumbering{arabic} 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.align = "center", class.source='klippy')
```
```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('top', 'right'),color = 'darkred',
               tooltip_message = 'Click to copy', tooltip_success = 'Done')
```

Always good to set a seed at the beginning of a practical where we will use simulated values 
```{r eval=TRUE}
set.seed=1234
```

# 1. Tune your Beta prior 

In each situation below, tune a Beta$(a,b)$ model that accurately reflects the given prior information. In many cases, there’s no single **right** answer, but rather multiple **reasonable** answers. Justify your answer.

  a. A scientist has created a new test for a rare disease. They expect that the test is accurate 80% of the time with a variance of 0.05

:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::

We get from this that we want a Beta with a mean=0.8 and a variance equal to 0.05. From the video on the Beta distribution (nb 7) we see that we can get to the $a$ and $b$ parameter using the inverse relationship:
$$a= \left[\frac{E(Y)(1-E(Y))}{V(Y)}-1\right]E(Y) = \left[\frac{0.8\times 0.2}{0.05}-1\right]\times 0.8=1.76$$
and
$$b = a \frac{1-E(Y)}{E(Y)}= 1.76 \times \frac{0.2}{0.8}=0.44$$
So we would use a Beta$(1.76,0.44)$ to reflect that prior information
::::

  b. Your friend applied to a job and tells you: *I think I have a 40% chance of getting the job, but I’m pretty unsure.* When pressed further, they put their chances between 20% and 60%. Hint: this is similar to the example we have seen in the lecture this morning.

:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::
This s similar to the example in the lecture 2.1 and using the same procedure above we can interpret the information above as follows:

```{r eval=TRUE}
mean=0.4
variance =0.01
# For the variance we consider that the interval of likely values is between 0.2 and 0.6;
# Using the Normal approximation we can say that the mean plus/minus 2 sd is between 0.2 and 0.6.
# So this means that the sd has to be 0.1 (and the variance 0.01)

#Now applying the formulas above:
a = (mean *(1-mean)/variance-1)*mean
b = a * (1-mean)/mean

a
b

# Let's check if the mean and variance of the Beta are what we expect
# We can simulate 1000 values from the Beta(a,b) and calculate mean and variance

beta_check = rbeta(10000,a,b)
mean(beta_check)
var(beta_check)
plot(density(beta_check), main="")
```
::::

  c. Your Aunt Jo is a successful mushroom hunter. She boasts: *I expect to find enough mushrooms to feed myself and my co-workers at the auto-repair shop 90% of the time, but if I had to give you a likely range it would be between 85% and 95% of the time.*

:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::  
From the information we have we get
```{r eval=TRUE}
mean = 0.9
variance = (0.1/4)^2
#Now applying the formulas above:
a = (mean *(1-mean)/variance-1)*mean
b = a * (1-mean)/mean

a
b

# Let's check if the mean and variance of the Beta are what we expect
# We can simulate 1000 values from the Beta(a,b) and calculate mean and variance

beta_check = rbeta(1000,a,b)
mean(beta_check)
var(beta_check)
#Now we can plot the probability distribution (using a different function than before)
x=seq(0,1,0.001)
plot(x,dbeta(x,a,b), type="l")
```
::::

# 2. Beta prior with no information

You want to specify a Beta prior for a situation in which you have no idea about some parameter $\theta$. You think  
$\theta$ is equally likely to be anywhere between 0 and 1.

  a. Specify and plot the appropriate Beta prior model.
  
  b. What is the mean of the Beta prior that you specified? Explain why that does or does not align with having no clue.
  
  c. What is the standard deviation of the Beta prior that you specified?
  

**HINT**: Use the functions `plot_beta()` and `summary_beta()` from the R package `bayesrules` to help you. Just note that in those functions our $\theta$ is called $\pi$.


:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::  
a. We want to specify a Uniform prior between 0 and 1. A Beta$(1,1)$ is equivalent to a Uniform between 0 and 1. Let's plot it.
```{r eval=TRUE}
library(bayesrules)
#Specify the parameters for the Beta
a=1; b=1
plot_beta(a,b)
```

b-c. We can get the mean of the Beta using `summary_beta()`
```{r eval=TRUE}
summarize_beta(a,b)
```

This aligns to lack of information, as each value in the interval 0-1 has equal probability a priori.  
::::


# 3. Tune your Gamma prior

In each situation below, tune a $Gamma(a,b)$ model for $\lambda$
  a. The mean of $\lambda$ is 4 and the variance is 12.
  
:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::

We know we want a Gamma with a mean=4 and a variance equal to 12. From the video on the Gamma distribution (nb 8) we see that we can get to the $a$ and $b$ parameter using the inverse relationship:
$$a= \frac{E(Y)^2}{V(Y)} = \frac{16}{12}=1.33$$
and
$$b = \frac{E(Y)}{V(Y)}= \frac{4}{12}=0.33$$
So we would use a Gamma$(1.33,0.33)$ to reflect that prior information
::::

  b. The mean of  $\lambda$ is 22 and the variance is 3.

:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::
From the information we have we get
```{r eval=TRUE}
mean = 22
variance = 3
#Now applying the formulas above:
a = mean^2/variance
b = mean/variance

a
b

# Let's check if the mean and variance of the Gamma are what we expect
# We can simulate 1000 values from the Gamma(a,b) and calculate mean and variance

gamma_check = rgamma(10000,a,b)
mean(gamma_check)
var(gamma_check)
#Now we can plot the probability distribution (using a different function than before)
x=seq(0,100,1)
plot(x,dgamma(x,a,b), type="l")
```
::::

# 4. Gamma with no information
Let $\lambda$ be the incidence ratio of Dengue in a Brazilian municipality in a specific year. We observe   
$y=24$ cases and know that the Expected value for that municipality is $N=20$.

  a. Specify a prior assuming we have no information on $\lambda$
  b. Why is the Poisson a reasonable choice for our data $Y$?
  c. Identify the posterior distribution for $\lambda$ 
  d. Plot the prior pdf, likelihood function (use the function `plot_poisson_likelihood()`), and posterior pdf of  $\lambda$. Describe the evolution in your understanding of $\lambda$ from the prior to the posterior.

:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::  
a. We want to specify a Uniform prior between 0 and $\infty$. This is much trickier than with the Beta (Have a go changing the parameters of the Gamma yourself). So we can settle for a Gamma with a very large variance. In literature generally a Gamma$(1,b)$ with a very small b is used as it ensures a large variance (how small the b you want to fix depends on the scale of the data). Let's plot a Gamma$(1,0.01)$.
```{r eval=TRUE}
library(bayesrules)
#Specify the parameters for the Gamma
a=1; b=0.1
plot_gamma(a,b)
```

b. The Poisson is a reasonable choice as $Y$ is the number of Dengue cases which is a discrete variable.

c. Using the formula seen in Lecture 2.1 we can combine the prior and data distribution to approximate the posterior using Bayes' theorem and obtain 
$$\lambda \mid y \sim Gamma(a+y, b+E)$$ Check this using the `summarize_gamma_poisson` function
```{r eval=TRUE}
y=24; E=20
a.post = y+a; b.post = b + E

# Let's check this using the 

summarize_gamma_poisson(a,b, 24, 20)
```

d. Finally we can plot the prior, data distribution and posterior:
```{r eval=TRUE}
#Prior
x = seq(0,5,0.001)
plot(x,dgamma(x,a,b), type="l", ylim=c(0,2), ylab="Density function", xlab=expression(lambda))
#Likelihood function
lambda <- seq(0,5, 0.001)
L <- (lambda *E)^y *exp(-lambda*E)/factorial(y)
lines(lambda,L, col="red")
#Posterior
lines(x,dgamma(x,a.post,b.post), col="green")
```
We can see that the posterior is very close to the likelihood function rather than to the prior. This is because the prior is non informative, so the posterior is driven by the data. 
::::

# 5. Beta-Binomial model

A local authority wants to study the efficacy of a public health intervention to encourage more children to walk to school. They collect data on one primary school and see that 130 out of 200 children walked regularly to school over the winter term. From the previous years they expect the proportion of children walking to school to be between 30% and 40%.

  a. Use the information from previous years to specify a prior for $\theta$ (proportion of children regularly walking to school)
  
  b. What is the data distribution?
  
  c. What is the posterior for $\theta$? 
  
  d. Would you conclude that the policy has been successful? Justify your answer.
  
  e. Assuming that the policy will be extended to all the primary schools in the local authorities over the next year, and knowing that the total number of children of primary school age are 1500, what would be the distribution of the number of children that will be regularly walking to school?
  
:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::  
  a. From previous years we know that we expect between 30% and 40% of children walking to school. We also want to use a Beta prior as we are estimating proportions. We can transform the previous information into a Beta distribution centered around 0.35 and spanning from 0.3 to 0.4, using a procedure similar to what we did for the previous exercise, so setting the sd as 0.1/4=0.025. Using the inverse relationship we get the following Beta parameters:
  
```{r eval=TRUE}
mean = 0.35
variance = 0.025^2

a = (mean *(1-mean)/variance-1)*mean
b = a * (1-mean)/mean

a
b

plot_beta(a,b)
```  
  b. As the data are the number of children walking (discrete variable) and we have the total population (total number of children in that primary school), we can specify a Binomial distribution on the data, $y \mid \theta \sim \text{Binomial}(\theta, n)$
  
  c. Using the conjugacy between Beta and Binomial we get that the posterior is anothe Beta distribution
  $$\theta \mid y=130 \sim \text{Beta}(a+y, b + n-y)$$
```{r eval=TRUE}
y = 130
n = 200
a.post = a + y
b.post = b + n - y 

plot_beta(a.post,b.post)
```  

  d. Comparing the prior and the posterior we would conclude that the policy has worked as it has increased the proportion of children walking - let's compare the means and variance for the prior and posterior. Remember that 
$$\text{mean of a Beta}(a,b) = \frac{a}{a+b}$$
and 
$$\text{variance of a Beta}(a,b) = \frac{ab}{(a+b)^2(a+b+1)}$$


```{r eval=TRUE}
mean.prior <- a/(a+b)
variance.prior <- (a*b)/((a+b)^2*(a+b+1))

mean.post <- a.post/(a.post+b.post)
variance.post <- (a.post*b.post)/((a.post+b.post)^2*(a.post+b.post+1))

mean.prior
mean.post

variance.prior
variance.post
```

  We see that the mean has increased from 0.35 to 0.45 and the variance has become smaller, suggesting that we have a more precise estimate in the posterior than in the prior.

  e. Now we want to extend the policy, but the council wants to know before that how many children will be walking to school, assuming that the policy will have the same success rate. So we need to *predict* how many children will be walking to school using the posterior predictive distribution which we have seen in Lecture 2.2. today. Practically, we simply need to generate values from a Binomial distribution with $n=1500$ (total number of children of primary school age in the local authority) and with $\theta \mid y \sim \text{Beta(a.post, b.post)}$

```{r eval=TRUE}
#First we generate a large sample from the posterior of theta
theta.post <- rbeta(1000,a.post,b.post)
#Then for each value of the posterior of theta, we generate a value for the posterior prediction of y
post.pred <- c()
for(i in 1:1000){
post.pred[i]<-rbinom(1,1500, theta.post[i])
}

mean(post.pred)
plot(density(post.pred),main="Posterior predictive distribution", xlab="number of children walking")
```  
::::



# 6. Gamma-Poisson model

A biologist hires you to study the density of a certain insect in the local region. Their prior idea about $\theta$, the number of insects per  
$m^2$ area, is well captured by a Gamma model with an expected value of $0.5$ insects per  $m^2$ and a variance of $0.25$ insects per $m^2$. You then go out to inspect 5 separate $m^2$ areas of a nearby field. You count 3, 2, 5, 1, 2 insects.

  a. What model, Normal or Poisson, should you use to model the dependence of your insect count data on the underlying insect density $\theta$? Explain why.
  
  b. Plot the prior probability function and posterior probability function of insect density  $\theta$
  
  c. What is the posterior mean and standard deviation of the insect density?
  
  d. Calculate the probability that the insect density is larger than 2 per $m^2$ (you can use an analytical approach or the MC simulative approach).

:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**Solution**
:::  
  a. As the number of insects can be described by a discrete random variable taking only positive values, the Poisson distribution is the most appropriate to model the dependency between the insect count data and underlying density
  
  b. First we get the parameters of the Gamma distribution using once again the inverse relationship with the mean and variance:
```{r eval=TRUE}
mean = 0.5
variance = 0.25
#Now applying the formulas above:
a = mean^2/variance
b = mean/variance
```

  Then we use the conjugacy to get the posterior (note that here we are considering the mean of the Poisson $\theta$ rather than the Incidence ratio $\lambda$ and to get the parameters of the posterior distribution we need to get the sum of all the $y$ and the number of sample (n=5) )
```{r eval=TRUE}
y=3+2+5+1+2; n=5
a.post = y+a; b.post = b + n
```
  Now we can plot prior and posterior

```{r eval=TRUE}
x <- seq(0,10,0.01)
plot(x,dgamma(x,a,b), main="",xlab=expression(theta), type="l", ylim=c(0,1), ylab="Density function")
lines(x,dgamma(x,a.post,b.post),col="red")
```
  c. The posterior mean and credible intervals can be obtained through the MC simulative approach, practically sampling from the posterior distribution of $\theta$ and then calculating the required statistics
```{r eval=TRUE}
theta.post <- rgamma(10000,a.post,b.post)

theta.mean <- mean(theta.post)
CI2.5 <- quantile(theta.post,0.025)
CI97.5 <- quantile(theta.post,0.975)

# Note that the can also obtain the mean analytically using the formula E(Y) = a/b
a.post/b.post
```
  d. Finally to get the probability that the insect density is larger than 2 per $m^2$ we can use two approaches:
```{r eval=TRUE}
#Analytical approach, where we calculate this probability
theta.prob2 <- 1-pgamma(2,a.post,b.post)
#MC simulative approach, using the previously simulated theta.post values
theta.post.MC <- theta.post>2
theta.prob.MC <- sum(theta.post.MC)/length(theta.post)

#Check if the MC simulation approximate well the probability of theta>2
theta.prob2
theta.prob.MC
```
  We can conclude that the MSc method approximate well the tail-probability for $\theta$. 
::::