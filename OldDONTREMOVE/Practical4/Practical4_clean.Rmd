---
title: "Hirarchical models, regression and model fit"
date: "Week 4"
output:
  html_document:
    css: practical.css
    toc: true
    toc_float: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = 'center', fig.width = 10, fig.height = 10)
```

# Malaria Prevalence in The Gambia

In this tutorial we will analyse the prevalence of malaria among children in The Gambia.

We start by importing the data:

```{r import}
# change this line to where you have the data saved
## remember to either use a double \\ or forward / for paths in r
dataPath <- 'C:/Users/cgascoig/OneDrive - Imperial College London/PUBH70061 Bayesian Modelling for SSTD 2022-23/Week 04/practicals/'
load(paste0(dataPath, 'gambia.RData'))

nrow(gambia)
head(gambia)
```
This dataset consists of observations about $N=500$ children living in The Gambia who were tested for malaria. For each child, the following variables are recorded and reported:

* `pos`: presence (1) or absence (0) of malaria in a blood sample taken from the child
* `age`: age of the child, in days
* `netuse`: indicator variable denoting whether (1) or not (0) the child regularly sleeps under a bed-net.
* `treated`: indicator variable denoting whether (1) or not (0) the bed-net is treated (coded 0 if netuse=0).
* `phc`: indicator variable denoting the presence (1) or absence (0) of a health centre in the village.

These variables are quite different in nature: `age` is a numeric variable, while `pos`, `netuse`, `treated` and `phc` are categorical variables, encoded into $1$ or $0$. When the categorical variable assumes only $2$ values (denoting the presence or absence of the character), they are typically called binary dummy variables.


## Model Specification

Our goal for the analysis is to assess whether the probability that a child has a positive test is affected by any of the aforementioned variables. Since the response variable `pos` is a binary variable, standard linear regression is not appropriate, and we turn to Generalized Linear Models instead.

One way to model these data is to fit a logistic regression model. We assume that for each child $i$ in village $j$, the presence or absence of malaria `pos`$_{ij}$ follows a Bernoulli distribution with parameter $p_{ij}$, so that \[P({\tt pos}_{ij} = 1 | \text{all the rest}) = p_{ij}\]. Using this,

  1. Write out a logistic regression model using a logit-link function to model the relationship between a positive malaria blood sample, age of the child, whether they regularly sleep under a bed-net, whether the bed-net is treated or not, and whether there is a health center in the village. In addition, include a random effect for the particular village the child lives in using the coordinates of the village $x$ and $y$ available in the dataset.

Remember that the *logit* transformation is equal to the log-odds, i.e. $$\hbox{logit}(p_{ij}) = \log \left(\frac{p_{ij}}{1 - p_{ij}}\right)$$ and is useful for transforming a probability (which is constrained to lie between 0 and 1) onto the range $(-\infty, +\infty)$.

## Model Fit

### Initial model

The following code can be used to define a village identification number from the co-ordinates:
```{r, eval = FALSE}
regData <- 
  gambia %>%
  # group by distinct combinations of x and y (longitude and latitude co-ordinates)
  dplyr::group_by(x, y) %>%
  # dplyr::cur_group_id() gives a unique identifier for the current group
  dplyr::mutate(village = dplyr::cur_group_id()) %>%
  # always ungroup once finished with group
  dplyr::ungroup()
```


  2. Implement the logistic regression written above in `r-inla`. Use `?inla()` to help work out arguments necessary to fit a model. Call this model `fit1`.
  
In a Bayesian analysis, we need to assume prior distributions for any unknown model parameters. In this case, we have specified the success rate parameters of the binomial ($p_{ij}$) as functions of regression coefficients and covariates, so we need to specify priors on the regression coefficients. As we will see later, the interpretation of the regression coefficient varies depending on the type of variable it refers to (i.e., binary or numerical), however the fitting procedure is unchanged.

We will choose vague, uniform priors for each coefficient (including the intercept):
\begin{eqnarray*}
\beta_j & \sim & \hbox{Normal}(\mu = 0, \tau = 1/100)\\
\end{eqnarray*}
```{r eval = TRUE, echo = FALSE, fig.height=5}
curve(dnorm(x, 0, 10), -50, 50)
```

In `r-inla`, the default priors for the intercept and fixed effects are
\begin{equation*}
  \begin{split}
    \beta_0 & \sim \text{Normal}(\mu = 0, \tau = 0) \\
    \beta_j & \sim \text{Normal}(\mu = 0, \tau = 0.001)
  \end{split}
\end{equation*}
where $\mu$ is the mean and $\tau = 1/\sigma^2$ is the precision (the inverse of the variance). It is important to remember that `r-inla` uses the precision rather than the standard deviation. To see the default priors for fixed effects in `r-inla`, we can type `inla.set.control.fixed.default()`. In order to change the priors on the fixed effects in `r-inla`, we need to edit the `control.fixed` argument in the `inla()` function. The `control.fixed` argument (and any of the other arguments starting with `control`, see `?inla()`) needs to be inputted as a list. 

  3. Using `?control.fixed`, update `fit1` to have the prior distributions of the intercept and model coefficients to be the ones specified above. HINT: look at the `mean`, `mean.intercept`, `prec`, and `prec.intercept` arguments. Keep the prior for the random effects the same (the `r-inla` default priors).

A great benefit of using `r-inla` is the avoidance of costly computation by performing a full Markov chain Monte Carlo simulation. This makes model fitting much quicker and means it is more practical to fit several models to test things such as the results sensitivity to the prior distribution choices. See the output in `summary(fit)` for the time used to run the model. The model should take several seconds to run whereas an MCMC evaluation of the same model may take up to a couple of minutes. We have exploited this feature already (and will continue to do so) by fitting a number of models which wouldâ€™ve taken longer if we used an MCMC evaluation. This speed up becomes increasingly important for larger datasets and with more complicated correlations between the coefficients.

The speed up offered using INLA is not to say that an INLA evaluation is the `be-all and end-all' for Bayesian modelling. A main advantage of MCMC is that samples from the joint posterior distribution are readily available. For INLA, we can use a Monte Carlo to obtain simulations from the posteriors of the linear predictor and marginal distributions - not the joint distribution. In addition, INLA works on a class of models call Latent Gaussian Models (LGMs). Whilst several models full under the LGM umbrella, this is a limitation in comparison to a MCMC evaluation which can be used for LGMs and other, more complicated models. 

As INLA focuses on marginal distributions, we want to exploit these and `r-inla` provides several functions that allow us to do this. The posterior densities of the marginals of the fixed effects are readily available from `$marginals.fixed`. We use the values given from `$marginals.fixed` in order to plot the marginal posterior densities, or in order to have a smoothed curve, we can use the function `inla.smarginal()`. This function uses spline interpolation between the points provided by `$marginals.fixed` to produce a smooth density plot.

  4. Using both `$marginals.fixed` and `inla.smarginal()`, plot the posterior distribution of the marginals and comment on the difference between the two curves.

### Model evalution and comparison

  5.a Looking at each of the marginals posterior distributions, do all of the coefficients have a practical importance in the model? That is, is the probability of a given coefficient significantly different from zero?
  
  5.b Based on your answer from 5.a, fit a new model with only those coefficients that offer a practical importance and call it `fit2`.
  
  5.c There are several different ways to compare between different models. One method is to use information-based metrics, such as WAIC, which account for model-fit and model complexity. Using `control.compute = list(waic = TRUE)` in the `inla()` call, re-run both `fit1` and `fit2` and compare their scores and comment on which model you would choose and why.

  5.d Using the model you choose in 5.c., fit a new model, `fit3`, which is the same but without a random effect. Use the WAIC criterion to decide if the random effect should be included or not.
  
### Model interpretation

A common statistic to quantify the strength of an association between an exposure and an outcome is the odds ratio, $\text{Odds Ratio} = \frac{\text{Odd of an event occurring}}{\text{Odd of an event not occurring}}$. An odds ratio (OR) greater than $1$ indicates an event (outcome) is more likely to occur when the predictor (exposure) increases. An odds ratio (OR) less than $1$ indicates an outcome is less likely to occur when the exposure increases. From a binomial model, we can calculate the ORs by taking the exponential of the coefficients.


  6. For the model you selected as the best fitting during Question 5, plot the posterior distribution of the marginal OR and comment on the interpretation of each of the coefficients.

### Posterior predictive checks

If the assumptions we made to fit the model are reasonable, then we should be able to generate data from the posterior distribution that is similar to the true data. Since we are fitting a binomial model, the `$fitted.values` are probabilities between $0$ and $1$. We can transform these probabilities into a Bernoulli random variable using `rbinom(n = 1, size = 1, prob = $fitted.values[i])` for a given fitted value. Here `n` is the number of observations we want to produce (we want one), `size` is the number of trials (since we want to generate a Bernoulli random variable, this will be one), and `prob` is the probability of success for each trial. 

  7. By transforming the probabilities from `$fitted.values` into a predicted observation for each child $i$ in village $j$, generate a set of predicted observations and compare these against the true observations.
  
### Extension: Full posterior samples

Previously we have used the `r-inla` outputs which are summaries of the marginals of the posterior distributions. For example, amongst other things  `$summary.fixed` will return a mean, standard deviation, 2.5%, 50% and 97.5% quantiles of the marginal posterior distribution. Whilst this is helpful, the full marginal posterior distributions are often needed.

In order to run `inla.posterior.sample()` with the model you have chosen, we need to rerun the model and include `control.compute = list(config = TRUE)` in the `inla()` call. Once this is done, we are able to use the `inla.posterior.sample()` function to generate full samples of the posterior distributions. As a minimum, we need to include the number of samples we wish to draw from the posterior distribution and the model fit in `inla.posterior.sample()`:
```{r, eval =  FALSE}
control.compute <- list(waic = TRUE, config = TRUE)
fit <- INLA::inla(..., control.compute = control.compute)
nSamples <- 1000
sampleAll <- INLA::inla.posterior.sample(result = fit, n = nSamples)
```

The output of `sampleAll` is a nested list of length `nSamples`. Use the following code to extract the relevant information from the list and put it into matrix format
```{r, eval = FALSE}
sampleMatrix <- 
  lapply(sampleAll, function(x) x$latent) %>%
  unlist() %>%
  matrix(., ncol = nSamples)
colnames(sampleMatrix) <- paste0('sample:', 1:nSamples)
rownames(sampleMatrix) <- rownames(sampleAll[[1]]$latent)
```

This matrix has 1000 columns, one for each of the samples from the posterior distribution and has 500+ rows. The rows 1- 500 are the posterior distributions for the linear predictor and the additional rows from 501 onwards are for the posterior distributions of the coefficients in the model. The code
```{r, eval = FALSE}
fit$misc$configs$contents
```
will show the name of the term (linear predictor, intercept, etc...) and where it starts (which we have constructed to correspond to the row of `sampleMatrix`). If you wanted to plot the posterior distribution of one of the marginals, then you would create a histogram using the data in the row of the term you are interested.

  8. Fit the model you have chosen, plot a histogram of the samples from the posterior distribution for each of model coefficients and superimpose the smooth plot of the marginal distribution used in Question 4 (e.g., using `inla.smarginal()`) and comment on what you see. 

