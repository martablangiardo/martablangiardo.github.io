<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Session 5: Spatio-temporal models for geostatistical data</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <!-- (Re)Defines a bunch of LaTeX commands that can then be used directly in the .Rmd file as '\command{...}' -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        /* This enables color macros */
        extensions: ["color.js"],
        Macros: {
          /* Probability & mathematical symbols */
          Pr: "{\\style{font-family:inherit; font-size: 110%;}{\\text{Pr}}}",
          exp: "{\\style{font-family:inherit; font-size: 105%;}{\\text{exp}}}",
          log: "{\\style{font-family:inherit; font-size: 105%;}{\\text{log}}}",
          ln: "{\\style{font-family:inherit; font-size: 105%;}{\\text{ln}}}",
          logit: "{\\style{font-family:inherit; font-size: 100%;}{\\text{logit}}}",
          HR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{HR}}}",
          OR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{OR}}}",
          E: "{\\style{font-family:inherit; font-size: 105%;}{\\text{E}}}",
          Var: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Var}}}",
          Cov: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Cov}}}",
          Corr: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Corr}}}",
          DIC: "{\\style{font-family:inherit; font-size: 105%;}{\\text{DIC}}}",
          se: "{\\style{font-family:inherit; font-size: 100%;}{\\text{se}}}",
          sd: "{\\style{font-family:inherit; font-size: 100%;}{\\text{sd}}}",
          kld: "{\\style{font-family:inherit; font-size: 100%;}{\\text{kld}}}",
          /* Distributions */
          dnorm: "{\\style{font-family:inherit;}{\\text{Normal}}}",
          dt: "{\\style{font-family:inherit;}{\\text{t}}}",
          ddirch: "{\\style{font-family:inherit;}{\\text{Dirichlet}}}",
          dmulti: "{\\style{font-family:inherit;}{\\text{Multinomial}}}",
          dbeta: "{\\style{font-family:inherit;}{\\text{Beta}}}",
          dgamma: "{\\style{font-family:inherit;}{\\text{Gamma}}}",
          dbern: "{\\style{font-family:inherit;}{\\text{Bernoulli}}}",
          dbin: "{\\style{font-family:inherit;}{\\text{Binomial}}}",
          dpois: "{\\style{font-family:inherit;}{\\text{Poisson}}}",
          dweib: "{\\style{font-family:inherit;}{\\text{Weibull}}}",
          dexp: "{\\style{font-family:inherit;}{\\text{Exponential}}}",
          dlnorm: "{\\style{font-family:inherit;}{\\text{logNormal}}}",
          dunif: "{\\style{font-family:inherit;}{\\text{Uniform}}}",
          /* LaTeX formatting */
          bm: ["{\\boldsymbol #1}",1],
          /* These create macros to typeset numbers in maths with the basic font */
          0: "{\\style{font-family:inherit; font-size: 105%;}{\\text{0}}}",
          1: "{\\style{font-family:inherit; font-size: 105%;}{\\text{1}}}",
          2: "{\\style{font-family:inherit; font-size: 105%;}{\\text{2}}}",
          3: "{\\style{font-family:inherit; font-size: 105%;}{\\text{3}}}",
          4: "{\\style{font-family:inherit; font-size: 105%;}{\\text{4}}}",
          5: "{\\style{font-family:inherit; font-size: 105%;}{\\text{5}}}",
          6: "{\\style{font-family:inherit; font-size: 105%;}{\\text{6}}}",
          7: "{\\style{font-family:inherit; font-size: 105%;}{\\text{7}}}",
          8: "{\\style{font-family:inherit; font-size: 105%;}{\\text{8}}}",
          9: "{\\style{font-family:inherit; font-size: 105%;}{\\text{9}}}",
          /* Health economics quantities */
          icer: "{\\style{font-family:inherit; font-size: 100%;}{\\text{ICER}}}",
          nb: "{\\style{font-family:inherit; font-size: 100%;}{\\text{NB}}}",
          ol: "{\\style{font-family:inherit; font-size: 100%;}{\\text{OL}}}",
          ceac: "{\\style{font-family:inherit; font-size: 100%;}{\\text{CEAC}}}",
          evpi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPI}}}",
          evppi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPPI}}}",
          evsi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVSI}}}"
        }
      }
    });
    </script>
    <link rel="stylesheet" href="assets/beamer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">






class: title-slide

# Session 5: Spatio-temporal models for geostatistical data&lt;span style="display:block; margin-top: 10px ;"&gt;&lt;/span&gt; 

## 

###     

### Geospatial Analytics using R and R-INLA 

&lt;!-- Can also separate the various components of the extra argument 'params', eg as in 
### Geospatial Analytics using R and R-INLA, , 
--&gt;



&lt;span style="display:block; margin-top: 150px ;"&gt;&lt;/span&gt;

.pull-left[
&lt;center&gt;&lt;img src=./img/MRCICLogo.png width='60%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;
] 

.pull-right[
&lt;center&gt;&lt;img src=./img/AIMSLogo.jpg width='60%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;
]
---

layout: true  

.my-footer[ 
.alignleft[ 
&amp;nbsp; &amp;copy; Marta Blangiardo | Monica Pirani 
]
.aligncenter[
Geospatial Analytics using R and R-INLA 
]
] 


---

# Learning Objectives

At the end of this session you should be able to:

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- know the definition of spatio-temporal process in the geostatistics framework;


&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- develop spatio-temporal models for geostatistics data;


&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;


- use `R-INLA` for implementing a (separable) space-time geostatistical models.


&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;


The topics covered in this lecture can be found in:

- Chapter 10 of the book **Geospatial Health Data: Modeling and Visualization with R-INLA and Shiny**  https://www.paulamoraga.com/book-geospatial/index.html

- Section 7.2 of the book **Spatio-Temporal Bayesian Models with `R-INLA`** https://sites.google.com/a/r-inla.org/stbook/

- Section 7.1 of the book **Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and INLA** https://becarioprecario.bitbucket.io/spde-gitbook/index.html

---

# Outline 

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

1\. [Spatio-temporal processes + a space-time hierarchical model for air pollution](#stprocess)

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

2\. [Implementation of a spatio-temporal model using `R-INLA`](#stinla)


---

name: stprocess
  
&lt;span style="display:block; margin-top: 250px ;"&gt;&lt;/span&gt;

.myblue[.center[.huge[
**Spatio-temporal processes + a space-time hierarchical model for air pollution**]]]



---

# Spatio-temporal processes

-  The concept of spatial process can be extended to the spatio-temporal case including a time dimension. The data are then defined by a process 
`\(\{y(s,t), (s,t) \in \mathcal D \subset \mathbb{R}^{2}\times \mathbb{R}\}\)`
and are observed at `\(n\)` spatial locations and at `\(T\)`  time points. 

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
- When spatio-temporal geostatistical data are considered, we need to define a valid .red[**spatio-temporal covariance function**] given by 
`$$\mbox{Cov}\left(y(\bm s_i,t), y(\bm s_j,u)\right)=\mathcal {C}(y_{it},y_{ju})$$`
--
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- If we assume .red[**stationarity in space and time**], the space-time covariance function can be written as a function of the spatial Euclidean distance `\(\Delta_{ij}=||\bm s_{i}-\bm s_{j}||\)` and of the temporal lag `\(\Lambda_{tu}=|t-u|\)` so that `\(\mbox{Cov}\left(y_{it}, y_{ju}\right)=\mathcal C(\Delta_{ij},\Lambda_{tu})\)`.

--
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
-  If we assume .red[**separability**] the stationary space-time covariance function is decomposed into the product of a purely spatial and a purely temporal term: `$$\mbox{Cov}\left(y_{it}, y_{ju}\right)=\mathcal{C}_1(\Delta_{ij})\mathcal{C}_2(\Lambda_{tu})$$`

---

# Hierarchical spatio-temporal model for PM concentrations [1]

- We present a spatio-temporal model for fine air particulate matter (PM2.5; particles less than 2.5 micrometers in diameter) measured yearly in Spain.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- The spatio-temporal model was firstly proposed by 
Cameletti, Lindgren, Simpson, and Rue (2013), while the data are from Moraga (2019).

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- These data have been collected over the years 2015 to 2017 from a set of sparse ground monitors.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- The .red[objective] of our analysis is to predict expected air pollution concentrations at arbitrary space-time locations from the observed data. This will allow us to construct high-resolution maps of air pollution for each year.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- The hierarchical spatio-temporal model that we use to reach this objective is a .red[separable model], where the space-time covariance structure can be decomposed into a spatial and a temporal term, i.e., the spatio-temporal covariance can be expressed as a Kronecker product of a spatial and a temporal covariance.

---

# Hierarchical spatio-temporal model for PM concentrations [2]


- We denote by `\(y_{it}\)` the PM2.5 concentrations measured at site `\(\bm s_i\)`, with `\(i=1,\ldots,n\)`, and year `\(t=1,\ldots,T\)`. 

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
- The following distribution is assumed for the observations:
`$$\color{blue}{y_{it}\sim \text{Normal}( \eta_{it},\sigma^2_e)}$$`
where `\(\sigma^{2}_{e}\)` is the variance of the measurement error defined by a Gaussian white-noise process, both serially and spatially uncorrelated.

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
- The linear predictor is given by
`$$\color{blue}{\eta_{it} = b_0 +  \omega_{it}}$$`
where `\(b_0\)`  is the intercept.

---

# Hierarchical spatio-temporal model for PM concentrations [3]

- The term `\(\omega_{it}\)` refers to the **latent spatio-temporal process** (i.e. the true unobserved level of pollution), which changes in time with first order autoregressive dynamics and spatially correlated innovations:

`$$\color{blue}{\omega_{it} = \rho\omega_{i(t-1)}+\xi_{it}}$$`
with `\(t=2,\ldots,T\)`, `\(|\rho|&lt;1\)`, `\(\omega_{i1}\sim\text{Normal}\left(0,\sigma^2/ (1-\rho^2)\right)\)`.

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
- The term `\(\xi_{it}\)` is a zero-mean **Gaussian field**, assumed to be **temporally independent** and characterized by the following spatio-temporal covariance function:

`$$\text{Cov}\left(\xi_{it},\xi_{ju}\right) =\left\{
\begin{array}[c]{ccc}%
0 &amp;  &amp;  \text{if} \qquad t\neq u\\
\text{Cov}(\xi_i,\xi_j) &amp;&amp; \text{if} \qquad t=u
\end{array}
\right.$$`

for `\(i\neq j\)`, where `\(\text{Cov}(\xi_i,\xi_j)\)` is given by Mat&amp;eacute;rn spatial covariance function.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
- This model is characterized by a **separable spatio-temporal covariance** as it can be rewritten as the product of a purely spatial and a purely temporal covariance function (see Cameletti, Ignaccolo, and Bande (2011)).

---

# Hierarchical spatio-temporal model for PM concentrations [4]

- For each time point `\(\bm \xi_t \sim \text{Normal}(\bm 0, \bm\Sigma)\)` and through the SPDE approach 
$$ \bm \xi_t \rightarrow \tilde{\bm \xi_t}\sim\text{Normal}(\bm 0,\bm Q^{-1}_S)$$
where the precision matrix `\(\bm Q_S\)` comes from the SPDE representation. The matrix `\(\bm Q_S\)`  does not change in time - due to the serial independence hypothesis - and its dimension is given by the number of vertices of the domain triangulation.

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
- The joint distribution of the `\(Tn\)`-dimensional GMRF `\(\bm\omega=(\bm\omega_1^\prime,\ldots,\bm\omega_T^\prime)^\prime\)` is 
`$$\bm\omega\sim\text{Normal}(\bm 0,\bm Q^{-1})$$`
with `\(\bm Q=\bm Q_T \otimes \bm Q_S\)`, where `\(\otimes\)` denotes the Kronecker product and `\(\bm Q_T\)` is the `\(T\)`-dimensional precision matrix of the AR(1) process.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- For the considered model the latent process is given by `\(\bm \theta=\{\bm \omega, b_0\}\)` while the hyperparameter vector is `\(\psi=(\sigma^2_e, \rho, \sigma^2, r)\)`.

---

name: stinla
  
&lt;span style="display:block; margin-top: 250px ;"&gt;&lt;/span&gt;

.myblue[.center[.huge[
**Implementation of a spatio-temporal process using `R-INLA`**]]]


---

# Particle matter data

- The data used to demonstrate the modelling framework are **PM2.5 concentrations** measured at several monitoring stations in Spain over the years 2015 to 2017 from the European Environment Agency. This example is taken from Moraga (2019), chapter 10.


.panelset[
.panel[.panel-name[Data]



```r
&gt; library(tidyverse)
&gt; library(INLA)
&gt; 
&gt; df = read.csv("data/dataPM25.csv")
&gt; df = df[, c(
+   "ReportingYear", "StationLocalId",
+   "SamplingPoint_Longitude",
+   "SamplingPoint_Latitude",
+   "AQValue"
+ )]
&gt; names(df) = c("year", "id", "long", "lat", "value")
```

]
.panel[.panel-name[Boundary]
.pull-left[

```r
&gt; library(lwgeom)
&gt; library(raster)
&gt; library(sf)
&gt; m = getData(name = "GADM", 
+     country = "Spain", level = 0) 
&gt; class(m)
```

```
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
```

]
.pull-right[
&lt;img src="./img/spainmap-1.png" &gt;
]
]
]

---

# Domain of the analysis [1]

- We are interested in predicting fine air particle in the main territory of Spain, and therefore we need to remove the islands from the map. 

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- To do so, we will keep the polygon of the map that has the largest area using the packages `sf` and `dplyr`. 

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- In detail, we will convert the object `m`, which is a `SpatialPolygonsDataFrame` object, to an `sf` object, and we will calculate the areas of the polygons of the object, and keep the polygon with the largest area.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- Additionally, we will transform our map to an object with UTM projection to work with meters. To do this, we use the `st_transform()` function specifying the ESPG code of Spain (code 25830) which  corresponds to UTM zone 30 North.


```r
&gt; library(ggplot2)
&gt; m = m %&gt;%
+   st_as_sf() %&gt;% #from sp to sf
+   st_cast("POLYGON") %&gt;% # convert to polygon
+   mutate(area = st_area(.)) %&gt;% # Extract geometric info (area)
+   arrange(desc(area)) %&gt;%
+   slice(1) # slices the data by row index
&gt; 
&gt; m = m %&gt;% st_transform(25830)
```

---

# Domain of the analysis [2]

.pull-left[

```r
&gt; ggplot(m) + geom_sf() + 
+   theme_bw() + coord_sf(datum = st_crs(m)) +
+   labs(x = "", y = "") 
```
]
.pull-right[

&lt;center&gt;&lt;img src=./img/MapUTM.jpeg width='60%' title=''&gt;&lt;/center&gt;
]


---

# Data preparation

- We now project the data which uses geographical coordinates (longitude and latitude) to UTM projection. 

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- We create an `sf` object with the longitude and latitude values of the monitoring stations, and set the CRS to EPSG 4326 which corresponds to geographical coordinates. Then we use `st_transform()` to project the data to EPSG code 25830 and we include such coordinates in our PM2.5 data set


```r
&gt; # from lon lat to UTM
&gt; p = st_as_sf(data.frame(long = df$long, lat = df$lat),
+               coords = c("long", "lat"))
&gt; st_crs(p) = st_crs(4326)
&gt; p = p %&gt;% st_transform(25830)
&gt; df[, c("x", "y")] = st_coordinates(p)
&gt; 
&gt; # keep station in the main territory of Spain
&gt; ind = st_intersects(m, p)
&gt; df = df[ind[[1]], ]
&gt; head(df)[1:5,]
```

```
  year          id      long      lat     value        x       y
1 2015 STA_ES1938A -3.690278 40.43972 11.022667 441457.6 4476793
3 2015 STA_ES0691A  2.204523 41.40388 17.963018 935101.1 4596682
4 2015 STA_ES1417A -0.403890 42.13611 11.332180 714552.3 4668151
5 2015 STA_ES1649A -1.744000 42.17600  6.366621 603732.6 4670081
6 2015 STA_ES1997A -6.147220 40.07778  7.034714 231636.0 4441138
```

---

# Map of particle data 

.pull-left[
We plot PM2.5 concentrations measured at the monitoring stations by year


```r
&gt; library(tidyverse)
&gt; library(viridis)
&gt; 
&gt; ggplot(m) + geom_sf() + coord_sf(datum = NA) +
+   geom_point(
+   data = df, aes(x = x, y = y, color = value),
+   size = 2) +
+   labs(x = "", y = "") +
+   scale_color_viridis() +
+   facet_wrap(~year, ncol = 2, nrow = 2) +
+   theme_bw()
```
]
.pull-right[
&lt;img src="./img/mapPM_3years_out-1.png" &gt;
]

---

# Create the mesh and the SPDE model

We obtain a triangulation of the domain using the function `inla.mesh.2d`

.pull-left[

```r
&gt; sc = 1/1000 ## scaling (so we go from m to Km)
&gt; coo = cbind(df$x, df$y)*sc
&gt; 
&gt; bnd = inla.nonconvex.hull(
+   st_coordinates(m)[, 1:2]*sc)
&gt; 
&gt; mesh = inla.mesh.2d(
+   loc = coo, boundary = bnd,
+   max.edge = c(100000, 200000)*sc, 
+   cutoff = 1000*sc)
```

Then we create the SPDE model using the `inla.spde2.matern` or `inla.spde2.pcmatern` functions. Here we use `inla.spde2.pcmatern` that adopts PC-priors for the model parameters range and marginal standard deviation.


```r
&gt; spde &lt;- inla.spde2.pcmatern(mesh = mesh, 
+   prior.range = c(7, 0.01), # P(range &lt; 7) = 0.01
+   prior.sigma = c(1, 0.01)) # P(sigma &gt; 1) = 0.01
&gt; spde$n.spde #n. of mesh vertices
```

```
[1] 706
```


]
.pull-right[
&lt;img src="./img/mesh-1.png" &gt;
]

---

# The index set

- The function `inla.spde.make.index`, generates vectors of indices for the spatial and temporal components of the model. We specify the name of the effect and the number of vertices in the SPDE model (`spde$n.spde`)

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;


```r
&gt; n_years = length(unique(df$year))
&gt; 
&gt; indexs = inla.spde.make.index("spatial.field",
+              n.spde = spde$n.spde,
+              n.group = n_years
+ )
&gt; names(indexs)
```

```
[1] "spatial.field"       "spatial.field.group" "spatial.field.repl" 
```

where:
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
 – `spatial.field`: indices of the SPDE vertices repeated the number of times,
 &lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
 – `spatial.field.group`: indices of the times repeated the number of mesh vertices,
 &lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
 – `spatial.field.repl`: vector of 1s with length given by the number of mesh vertices times the number of times (`spde$n.spde*n_years`; because we have a
single replication of the spatial process at each time point).


---

# A matrix for the estimation part

- We construct an observation matrix that extracts the values of the spatio-temporal field at the measurement locations and time points used for the parameter estimation. This is the .red[projection matrix A], that is used to project the Gaussian random field from the observations to the triangulation vertices

- The projection matrix is defined using the coordinates of the observed data. In order to construct a Kronecker product model in `R-INLA`, we use the
`group` feature in the `inla.spde.make.A`

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;


```r
&gt; group = df$year - min(df$year) + 1
&gt; A_est = inla.spde.make.A(mesh = mesh, loc = coo, group = group)
&gt; dim(A_est) 
```

```
[1]  299 2118
```

This is a matrix equal in dimension to (number of observations) `\(\times\)` (number of indices) of our basis functions in space and time:


```r
&gt; nrow(df)
```

```
[1] 299
```

```r
&gt; length(indexs$spatial.field)
```

```
[1] 2118
```

---

# Grid locations for predictions [1]

- We want to calculate predictions of the expected particle concentrations for the entire Spain. 

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- To do so, we need to create a **spatial grid** upon which we map the predictions. Here, we create an 50 `\(\times\)` 50 grid. 



```r
&gt; # Grid construction
&gt; bb = st_bbox(m)
&gt; x = seq(bb$xmin - 1, bb$xmax + 1, length.out = 50)
&gt; y = seq(bb$ymin - 1, bb$ymax + 1, length.out = 50)
&gt; dp = as.matrix(expand.grid(x, y))
&gt; #plot(dp, asp = 1, xlab="", ylab="")
```

&lt;center&gt;&lt;img src=./img/grid1.jpg width='43%' title=''&gt;&lt;/center&gt;
---

# Grid locations for predictions [2]

- We intersect the created grid with the map of Spain, to keep only the locations that lie within that map 


```r
&gt; # keep only locations within borders of Spain
&gt; p = st_as_sf(data.frame(x = dp[, 1], y = dp[, 2]),
+             coords = c("x", "y"))
&gt; st_crs(p) = st_crs(25830)
&gt; ind = st_intersects(m, p)
&gt; dp = dp[ind[[1]], ]
&gt; #plot(dp, asp = 1, xlab="", ylab="")
```

&lt;center&gt;&lt;img src=./img/grid2.jpg width='43%' title=''&gt;&lt;/center&gt;

---

# Grid for predictions &amp; A matrix for the predicton part

- Finally, as we want to predict over three years, we bind three times the coordinates  at the prediction points, specifying the times as: time 1 for 2015, time 2 for 2016, and time 3 for 2017.

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;


```r
&gt; dp_final = rbind(cbind(dp, 1), cbind(dp, 2), cbind(dp, 3))
&gt; head(dp_final)
```

```
         Var1    Var2  
[1,] 260558.8 4004853 1
[2,] 218306.0 4022657 1
[3,] 239432.4 4022657 1
[4,] 260558.8 4022657 1
[5,] 281685.2 4022657 1
[6,] 218306.0 4040460 1
```


```r
&gt; # A matrix for predictions
&gt; coo_pred = dp_final[, 1:2]*sc
&gt; groupp = dp_final[, 3]
&gt; A_pred &lt;- inla.spde.make.A(mesh = mesh, 
+                            loc = coo_pred, # prediction locations
+                            group = groupp) # time indices 
```
---

# Data stack preparation

To make predictions, we need to construct the .red[stacks for the estimation and prediction, then to join them]:

- First we build the estimation stack:

```r
&gt; stack_est &lt;- inla.stack(
+   tag = "est",
+   data = list(y = df$value),
+   A = list(1, A_est),
+   effects = list(data.frame(b0 = rep(1, nrow(df))), indexs))
```

- Then, to predict within the `inla` fitting function, we need to create a stack also for prediction. Note that for the response in the prediction stack we will set it to `\(y=\)`NA:

```r
&gt; stack_pred = inla.stack(
+   tag = "pred",
+   data = list(y = NA),
+   A = list(1, A_pred),
+   effects = list(data.frame(b0 = rep(1, nrow(dp_final))), indexs))
```

- Lastly, we join the prediction and observed data stack together

```r
&gt; stack = inla.stack(stack_est, stack_pred)
```

---

# Define the formula

- We define the formula, specifying a PC prior for the temporal correlation parameter `\(\rho\)` linked to the AR(1) model, such that `\(p(\rho&gt;0=0.9)\)`


```r
&gt; rho_hyper = list(theta = list(prior = "pccor1", param = c(0, 0.9)))
&gt; 
&gt; formula = y ~ -1 + b0 + f(spatial.field,
+                           model = spde, group = spatial.field.group,
+                           control.group = list(model = "ar1", hyper = rho_hyper))
```

Note that using the options `group` and `control.group` we specify that at each time point the spatial locations are linked by the `spde` model object, while across time the process evolves according to an AR(1) dynamics.


---

# Fit the space-time model!


```r
&gt; fit = inla(formula,
+           data = inla.stack.data(stack, spde=spde),
+           family = "gaussian",
+           control.predictor = list(A = inla.stack.A(stack), compute = TRUE),
+           control.compute = list(return.marginals.predictor = TRUE))
```


```r
&gt; round(fit$summary.fixed[,c("mean","0.025quant","0.975quant")],3)
```

```
   mean 0.025quant 0.975quant
b0 8.57      8.006       9.14
```


```r
&gt; round(fit$summary.hyperpar, 3)
```

```
                                          mean    sd 0.025quant 0.5quant 0.975quant   mode
Precision for the Gaussian observations  0.855 0.169      0.565    0.840      1.229  0.814
Range for spatial.field                 18.886 1.847     15.485   18.805     22.750 18.663
Stdev for spatial.field                  4.735 0.361      4.065    4.721      5.486  4.694
GroupRho for spatial.field               0.963 0.015      0.928    0.965      0.985  0.970
```

---

# Marginal posterior distribution of the intercept `\(b0\)`


```r
&gt; modfix = fit$summary.fixed
&gt; modfix
```

```
       mean       sd 0.025quant 0.5quant 0.975quant     mode          kld
b0 8.570385 0.288333    8.00565 8.569599   9.139608 8.569605 1.587105e-08
```

```r
&gt; plot(fit$marginals.fix$b0,type ='l',xlab=expression(beta[0]),ylab="density")
&gt; abline(v = modfix[1, c(3, 5)], lty=2)
```
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/b0.png width='43%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

---

# Plot of the posterior distribution of the temporal correlation `\(\rho\)` 


```r
&gt; # AR1 parameter    
&gt; plot(fit$marginals.hyperpar$`GroupRho for spatial.field`,
+      type = 'l',xlab = expression(rho),ylab = "density", xlim=c(0.8,1))
```

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

&lt;center&gt;&lt;img src=./img/rho.png width='43%' title=''&gt;&lt;/center&gt;

We can see that the AR(1) coefficient of the latent field, `\(\rho\)`, is large and most of the mass of the posterior distribution is close to 1.
---

# Plot of the variance and range parameters [1]

- We use the function `inla.spde2.result` to extract field and parameter values and distributions for the `inla.spde` SPDE effect from the INLA result object


```r
&gt; output.field = inla.spde2.result(inla = fit,
+                                   name = "spatial.field",
+                                   spde = spde,
+                                   do.transf = TRUE)
```

- Then we plot the parameters of the spatial field 

```r
&gt; par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
&gt; 
&gt; plot(output.field$marginals.variance.nominal[[1]],type = 'l',
+      xlab = expression(sigma^2),ylab = "density")
&gt; 
&gt; plot(output.field$marginals.range.nominal[[1]],type = 'l',
+      xlab = "spatial range",ylab = "density") 
```

---

# Plot of the variance and range parameters [2]

&lt;center&gt;&lt;img src=./img/Plot_Var_Range.jpeg width='47%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

---

# Map of the predicted particle concentrations (and 95% CI) by year 

- To map the predicted concentrations of PM2.5, we need (i) to extract the indices to the prediction nodes, and then (ii) to extract the posterior mean (and related 95%CI) of the response. We use `inla.stack.index()` to obtain the indices of the `stack` that correspond to `tag = "pred"`


```r
&gt; index = inla.stack.index(stack = stack, tag = "pred")$data
&gt; dp_final = data.frame(dp_final)
&gt; names(dp_final) = c("x", "y", "time")
&gt; # posterior mean
&gt; dp_final$pred_mean = fit$summary.fitted.values[index, "mean"]
&gt; # lower limits of the 95% credible intervals
&gt; dp_final$pred_ll = fit$summary.fitted.values[index, "0.025quant"] 
&gt; # upper limits of the 95% credible intervals
&gt; dp_final$pred_ul = fit$summary.fitted.values[index, "0.975quant"]
&gt; 
&gt; library(reshape2)
&gt; dpm = melt(dp_final, # melt dp_final into a long data frame 
+             id.vars = c("x", "y", "time"),
+             measure.vars = c("pred_mean", "pred_ll", "pred_ul"))
&gt; head(dpm)[1:3,]
```

```
         x       y time  variable    value
1 260558.8 4004853    1 pred_mean 8.570392
2 218306.0 4022657    1 pred_mean 8.570392
3 239432.4 4022657    1 pred_mean 8.570392
```
---

# And finally the yearly maps for PM2.5 concentrations!

```r
&gt; # map of posterior means and associated uncertainty
&gt; ggplot(m) + geom_sf() + coord_sf(datum = NA) + 
+   geom_tile(data = dpm, aes(x = x, y = y, fill = value)) + labs(x = "", y = "") +
+   facet_wrap(variable ~ time) + scale_fill_viridis("PM2.5") + theme_bw()
```

&lt;center&gt;&lt;img src=./img/Maps_predictions.jpg width='39%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;
---

# Model Validation

- An important aspect of Bayesian modelling regards the assessment of its plausibility and fit.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

-  We studied different techniques that can be use to select the best model for the data in analysis, such as the DIC or the WAIC.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- In particular for point-level (geostatistical) spatial and spatio-temporal models, validation through the  evaluation on the predictive performance is extremely important.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- In this last section of this lecture we introduce an additional technique for the validation of our model(s), such as cross-validation.

---

# Idea about cross-validation

- Once we have fitted the model, we may want to know about the performance of the resulting spatial or spatio-temporal process model. This can be performed by cross-validation.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- Cross-validation is a methodology used to evaluate model prediction performance by splitting up the data set into a .red[training sample] and a .red[validation sample], then fitting the model with the training sample and evaluating it with the validation sample.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

-  This methodology allow us to evaluate how well our model reproduces the real-world quantities.

---

# Cross-validation and `\(k\)`-fold cross-validation

- Specifically, to perform this validation assessment, we split the data set into two disjoint subsets. One of these subsets is used to learn the parameters and the other subset is our validation (or test) set used to estimate the mean test error.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

-  Dividing the data set into a fixed training set and a fixed validation set can be problematic if it results in a validation set being small.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- In the situation of small data set, there are alternative procedures, which are based on the idea of repeating the training and validation (testing) computation on different randomly chosen subsets of the original data set.

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

- The most common of these is the .blue[*k*-fold cross-validation], where a (random) partition of the data set is formed by splitting it into *k* nonoverlapping subsets. The results from the different partitions are then combined to produce single estimations of the error.
---

# Metrics used for evaluating prediction performance

- A number of criteria can be used to evaluate the predictive capability of competing models. 
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
- Let's introduce first the notation:

  - `\(m\)` is the total number of observations we want to validate

  - `\(y_i\)` is the data indexed by `\(i\)`

  - `\(\hat{y}_i\)` is the prediction value


- Some popular metrics are:
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
  - .blue[Mean Squared Error]: `\(MSE=\frac{1}{m}\sum_{i=1}^{m}(\hat{y}_i-y_i)^2\)`
  &lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
  - .blue[Root Mean Squared Error]: `\(RMSE=\sqrt{\frac{1}{m}\sum_{i=1}^{m}(\hat{y}_i-y_i)^2}\)`
  &lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
  - .blue[Mean Absolute Error]: `\(MAE=\frac{1}{m}\sum_{i=1}^{m}|\hat{y}_i-y_i|\)`
  &lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
  - .blue[Mean Absolute Percentage Error]: `\(MAPE=\frac{1}{m}\sum_{i=1}^{m}|(\hat{y}_i-y_i)/y_i|\)`
  &lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
  - .blue[Bias]: `\(BIAS=(\hat{y}_i-y_i)\)`

---

# References

Cameletti, M., R. Ignaccolo, and S. Bande (2011). "Comparing spatio-temporal models for particulate matter in Piemonte". In: _Environmetrics_ 22.8, pp. 985-996.

Cameletti, M., F. Lindgren, D. Simpson, et al. (2013). "Spatio-temporal modeling of particulate matter concentration through the SPDE approach". In: _AStA Advances in Statistical Analysis_ 97, pp. 109-131.

Moraga, P. (2019). _Geospatial health data: Modeling and visualization with R-INLA and shiny_. CRC Press.

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="assets/remark-zoom.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"navigation": {
"scroll": false
},
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
